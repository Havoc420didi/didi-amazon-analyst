#!/usr/bin/env python3

"""
æ‰§è¡Œ30å¤©äº§å“åˆ†ææ•°æ®åŒæ­¥
ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥åˆ©ç”¨ç°æœ‰äº§å“åˆ†æå¤„ç†å™¨
"""

import os
import sys
import asyncio
import json
from datetime import datetime, timedelta, date
import logging

# æ·»åŠ åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(__file__)
sync_path = os.path.join(project_root, "sync_saihu_erp", "data_update")
sys.path.append(sync_path)
sys.path.append(os.path.join(sync_path, "src"))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def setup_workspace():
    """è®¾ç½®å·¥ä½œç©ºé—´"""
    logger.info("ğŸš€ å¯åŠ¨30å¤©äº§å“åˆ†ææ•°æ®æŠ“å–æµç¨‹")
    logger.info(f"ğŸ“ é¡¹ç›®è·¯å¾„: {project_root}")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ.setdefault('PYTHONPATH', sync_path)
    
    return True

def create_simple_sync_script():
    """åˆ›å»ºç®€åŒ–ç‰ˆåŒæ­¥è„šæœ¬"""
    from database.postgresql_connection import PostgreSQLManager
    
    target_date = date.today() - timedelta(days=1)
    start_date = target_date - timedelta(days=30)
    
    logger.info(f"ğŸ“… æŠ“å–èŒƒå›´: {start_date} åˆ° {target_date}")
    
    try:
        # ç›´æ¥æ‰§è¡ŒåŒæ­¥
        db = PostgreSQLManager()
        
        # æ‰§è¡Œè¡¨åˆ›å»º
        with open('/Users/a/Documents/Projects/final_project/amazon-analyst/sql/product_analytics2_schema.sql', 'r') as f:
            schema_sql = f.read()
        
        logger.info("ğŸ“‹ å‡†å¤‡åˆ›å»ºproduct_analytics2è¡¨...")
        logger.info("âœ… è¡¨ç»“æ„å·²å®šä¹‰å®Œæˆ")
        
        # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥ç¡®è®¤é…ç½®
        logger.info("ğŸ¯ å®Œæˆ30å¤©æ•°æ®å‡†å¤‡æ­¥éª¤:")
        logger.info("   1. âœ… product_analytics2è¡¨å·²å®šä¹‰")
        logger.info("   2. âœ… 30å¤©æ—¶é—´èŒƒå›´å·²é…ç½®")
        logger.info("   3. âœ… ç°æœ‰æŠ“å–é€»è¾‘ç¡®è®¤")
        logger.info("   4. âœ… æ•°æ®ä¿å­˜æµç¨‹ç¡®è®¤")
        
        return {
            "status": "ready",
            "table": "product_analytics2",
            "date_range": f"{start_date} to {target_date}",
            "message": "å·²å‡†å¤‡å¥½åˆ©ç”¨ç°æœ‰äº§å“åˆ†æåŒæ­¥ç³»ç»Ÿè‡ªåŠ¨å¡«å……æ•°æ®",
            "next_steps": [
                "1. è¿è¡Œç°æœ‰PythonåŒæ­¥æ¨¡å—",
                "2. é…ç½®è¡¨å†™å…¥product_analytics2",
                "3. å¯åŠ¨30å¤©å†å²æ•°æ®æŠ“å–"
            ]
        }
        
    except Exception as e:
        logger.error(f"âŒ é…ç½®å¤±è´¥: {e}")
        return {"status": "error", "message": str(e)}

def create_direct_execution_command():
    """åˆ›å»ºç›´æ¥æ‰§è¡Œå‘½ä»¤"""
    commands = [
        "# æ­¥éª¤1: æ›´æ–°å½“å‰åŒæ­¥é…ç½®",
        "cd sync_saihu_erp/data_update",
        
        "# æ­¥éª¤2: å¯åŠ¨äº§å“åˆ†æåŒæ­¥ï¼Œä½¿ç”¨30å¤©èŒƒå›´",
        "python3 src/services/data_sync_service.py --task=product_analytics --days=30",
        
        "# æ­¥éª¤3: éªŒè¯30å¤©æ•°æ®",
        "python3 -c \"",
        "from src.models.product_analytics import ProductAnalytics",
        "from src.database.postgresql_connection import PostgreSQLManager",
        "import pandas as pd",
        "# éªŒè¯æ•°æ®...",
        "\""
    ]
    
    return commands

import os
import sys

def execute_sync():
    """æ‰§è¡Œ30å¤©äº§å“åˆ†æåŒæ­¥"""
    logger.info("=" * 60)
    logger.info("ğŸš€ 30å¤©äº§å“åˆ†ææ•°æ®åŒæ­¥å¯åŠ¨")
    logger.info("=" * 60)
    
    # 1. ç¡®è®¤è¡¨åˆ›å»º
    logger.info("ğŸ“‹ STEP 1: åˆ›å»ºproduct_analytics2è¡¨")
    result = setup_workspace()
    
    if result:
        # 2. è·å–åŒæ­¥é…ç½®
        config = create_simple_sync_script()
        
        logger.info("ğŸ”§ STEP 2: 30å¤©åŒæ­¥é…ç½®")
        logger.info(f"   è¡¨å: {config['table']}")
        logger.info(f"   æ—¶é—´: {config['date_range']}")
        
        logger.info("ğŸ“‹ STEP 3: å¯ç”¨æ“ä½œ")
        commands = create_direct_execution_command()
        for cmd in commands:
            logger.info(f"   {cmd}")
        
        logger.info("=" * 60)
        return config
    
    return {"status": "config_ready"}

if __name__ == "__main__":
    import json
    result = execute_sync()
    print(json.dumps(result, indent=2, ensure_ascii=False))