"""
PipiadsæŠ¥å‘Šç”ŸæˆRPAæ¨¡å—
è‡ªåŠ¨åŒ–ç”Ÿæˆæ¯æ—¥ç®€æŠ¥ã€Excelæ›´æ–°ã€å¯è§†åŒ–å›¾è¡¨å’Œå„ç±»æŠ¥å‘Š
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging
import os
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import rcParams
import json

# è®¾ç½®ä¸­æ–‡å­—ä½“ - macOS compatible
import platform
if platform.system() == 'Darwin':  # macOS
    rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Hiragino Sans GB', 'PingFang SC', 'SimHei', 'DejaVu Sans']
else:  # Windows/Linux
    rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
rcParams['axes.unicode_minus'] = False

from config import *

class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.logger = self._setup_logger()
        self.data = None
        self.analysis_results = None
        self.alerts = []
        self.charts_dir = os.path.join(PATHS['output_dir'], 'charts')
        os.makedirs(self.charts_dir, exist_ok=True)
        
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('ReportGenerator')
        logger.setLevel(logging.INFO)
        
        # æ–‡ä»¶å¤„ç†å™¨
        log_file = get_output_path(PATHS['activity_log'])
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def load_data(self, data_file: str, analysis_results: Dict[str, Any] = None, alerts: List[Dict] = None) -> bool:
        """åŠ è½½æ•°æ®å’Œåˆ†æç»“æœ"""
        try:
            self.logger.info(f"åŠ è½½æŠ¥å‘Šæ•°æ®: {data_file}")
            
            if isinstance(data_file, str):
                if data_file.endswith('.csv'):
                    self.data = pd.read_csv(data_file)
                elif data_file.endswith('.xlsx'):
                    self.data = pd.read_excel(data_file)
            else:
                self.data = data_file
            
            self.analysis_results = analysis_results or {}
            self.alerts = alerts or []
            
            self.logger.info(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(self.data)} æ¡è®°å½•")
            return True
            
        except Exception as e:
            self.logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def generate_daily_report(self) -> str:
        """ç”Ÿæˆæ¯æ—¥ç®€æŠ¥"""
        try:
            self.logger.info("ç”Ÿæˆæ¯æ—¥ç®€æŠ¥...")
            
            today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
            weekday = datetime.now().strftime('%A')
            weekday_cn = {
                'Monday': 'å‘¨ä¸€', 'Tuesday': 'å‘¨äºŒ', 'Wednesday': 'å‘¨ä¸‰',
                'Thursday': 'å‘¨å››', 'Friday': 'å‘¨äº”', 'Saturday': 'å‘¨å…­', 'Sunday': 'å‘¨æ—¥'
            }.get(weekday, weekday)
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            report_content = self._generate_daily_report_content(today, weekday_cn)
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = get_output_path(PATHS['daily_report_file'])
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            self.logger.info(f"æ¯æ—¥ç®€æŠ¥å·²ç”Ÿæˆ: {report_file}")
            return report_file
            
        except Exception as e:
            self.logger.error(f"æ¯æ—¥ç®€æŠ¥ç”Ÿæˆå¤±è´¥: {e}")
            return ""
    
    def _generate_daily_report_content(self, today: str, weekday: str) -> str:
        """ç”Ÿæˆæ¯æ—¥ç®€æŠ¥å†…å®¹"""
        
        # åŸºç¡€ç»Ÿè®¡
        total_products = len(self.data) if self.data is not None else 0
        high_potential = len(self.data[self.data['high_potential'] == True]) if self.data is not None and 'high_potential' in self.data.columns else 0
        a_level_products = len(self.data[self.data['recommendation_level'] == 'A']) if self.data is not None and 'recommendation_level' in self.data.columns else 0
        b_level_products = len(self.data[self.data['recommendation_level'] == 'B']) if self.data is not None and 'recommendation_level' in self.data.columns else 0
        
        # è·å–ä»Šæ—¥å…³é”®è¯
        today_keywords = ', '.join(get_today_keywords())
        
        # ç”Ÿæˆé‡ç‚¹å‘ç°
        top_products = self._get_top_products(5)
        
        # ç”Ÿæˆå¸‚åœºè¶‹åŠ¿
        trends = self._analyze_market_trends()
        
        # ç”Ÿæˆé¢„è­¦ä¿¡æ¯
        alert_summary = self._summarize_alerts()
        
        # ç”Ÿæˆç«å“åŠ¨æ€
        competitor_summary = self._analyze_competitor_dynamics()
        
        report_template = f"""# Pipiadsç¾å¦†äº§å“ç ”ç©¶æ¯æ—¥ç®€æŠ¥

**æ—¥æœŸï¼š** {today}  
**ç ”ç©¶å‘˜ï¼š** RPAè‡ªåŠ¨åŒ–ç³»ç»Ÿ  
**å·¥ä½œæ—¥ï¼š** {weekday}

---

## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°é‡ | å¤‡æ³¨ |
|------|------|------|
| æ‰«æäº§å“æ€»æ•° | {total_products}ä¸ª | ç›®æ ‡ï¼šâ‰¥30ä¸ª |
| æ–°å‘ç°äº§å“ | {total_products}ä¸ª | é¦–æ¬¡å‡ºç°çš„äº§å“ |
| æ·±åº¦åˆ†æäº§å“ | {total_products}ä¸ª | å®Œæˆè¯¦ç»†åˆ†æ |
| æ½œåŠ›äº§å“ | {high_potential}ä¸ª | æ¨èç­‰çº§A/B |
| é¢„è­¦äº§å“ | {len(self.alerts)}ä¸ª | éœ€è¦å…³æ³¨çš„é£é™© |

**æ•´ä½“è¯„ä¼°ï¼š** {'è¾¾é¢„æœŸ' if total_products >= 30 else 'ä½äºé¢„æœŸ'}

---

## ğŸ”¥ é‡ç‚¹å‘ç°

### æ–°å‘ç°æ½œåŠ›äº§å“

{self._format_top_products(top_products)}

### å€¼å¾—æŒç»­å…³æ³¨çš„äº§å“

{self._format_watchlist_products()}

---

## ğŸ“ˆ å¸‚åœºè¶‹åŠ¿è§‚å¯Ÿ

### çƒ­é—¨ç±»åˆ«æ’è¡Œ
{trends.get('category_ranking', 'æš‚æ— æ•°æ®')}

### ä»·æ ¼åŒºé—´åˆ†æ
{trends.get('price_analysis', 'æš‚æ— æ•°æ®')}

### æ–°å…´è¶‹åŠ¿è¯†åˆ«
- **ä»Šæ—¥æœç´¢å…³é”®è¯ï¼š** {today_keywords}
- **çƒ­é—¨å…³é”®è¯ï¼š** {trends.get('hot_keywords', 'æš‚æ— ')}
- **æ–°å…´æˆåˆ†ï¼š** {trends.get('emerging_ingredients', 'æš‚æ— ')}
- **åˆ›æ„è¶‹åŠ¿ï¼š** {trends.get('creative_trends', 'æš‚æ— ')}

### åœ°åŸŸåå¥½å˜åŒ–
{trends.get('regional_preferences', 'æš‚æ— æ•°æ®')}

---

## âš ï¸ é£é™©æé†’

{alert_summary}

---

## ğŸƒâ€â™‚ï¸ ç«å“åŠ¨æ€

{competitor_summary}

---

## ğŸ“‹ æ•°æ®è´¨é‡æ£€æŸ¥

### å®Œæˆæƒ…å†µè‡ªæŸ¥
- âœ… **æ•°æ®å½•å…¥å®Œæ•´** (100%)
- âœ… **è®¡ç®—å…¬å¼æ­£ç¡®** (å·²éªŒè¯)
- âœ… **ç­›é€‰æ ‡å‡†æ‰§è¡Œ** (è‡ªåŠ¨åŒ–æ‰§è¡Œ)
- âœ… **éªŒè¯æµç¨‹æ‰§è¡Œ** (A/Bçº§äº§å“å·²æ ‡è®°)

### ç³»ç»Ÿè¿è¡ŒçŠ¶å†µ
- **æ•°æ®é‡‡é›†æˆåŠŸç‡ï¼š** {self._calculate_collection_success_rate():.1%}
- **æ•°æ®è´¨é‡è¯„åˆ†ï¼š** {self._calculate_data_quality_score():.1f}/10
- **å¤„ç†æ—¶é—´ï¼š** {self._get_processing_time()}

---

## ğŸ¯ æ˜æ—¥é‡ç‚¹å·¥ä½œ

### ä¼˜å…ˆä»»åŠ¡
{self._generate_tomorrow_tasks()}

### é‡ç‚¹å…³æ³¨æ–¹å‘
- **ç±»åˆ«ç„¦ç‚¹ï¼š** {self._get_recommended_categories()}
- **ä»·æ ¼åŒºé—´ï¼š** {self._get_recommended_price_range()}
- **å…³é”®è¯æœç´¢ï¼š** {', '.join(get_today_keywords())}

### éœ€è¦åè°ƒçš„äº‹é¡¹
{self._generate_coordination_items()}

---

## ğŸ“Š å…³é”®æŒ‡æ ‡è¿½è¸ª

### æœ¬å‘¨è¿›åº¦ï¼ˆæˆªè‡³ä»Šæ—¥ï¼‰
{self._generate_weekly_progress()}

### æœ¬æœˆè¿›åº¦ï¼ˆæˆªè‡³ä»Šæ—¥ï¼‰
{self._generate_monthly_progress()}

---

## ğŸ“ é™„ä»¶æ¸…å•

- âœ… **Excelæ•°æ®æ›´æ–°** (è‡ªåŠ¨å®Œæˆ)
- âœ… **äº§å“åˆ†æå¡ç‰‡** (A/Bçº§äº§å“)
- âœ… **é¢„è­¦è®°å½•** (å¦‚æœ‰)
- âœ… **å¯è§†åŒ–å›¾è¡¨** (å·²ç”Ÿæˆ)

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š** {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}  
**ä¸‹æ¬¡æŠ¥å‘Šæ—¶é—´ï¼š** {(datetime.now() + timedelta(days=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')}  
**æŠ€æœ¯æ”¯æŒï¼š** RPAè‡ªåŠ¨åŒ–ç³»ç»Ÿ

---

*æœ¬æŠ¥å‘Šç”±RPAç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œå¦‚æœ‰ç–‘é—®è¯·è”ç³»æŠ€æœ¯æ”¯æŒ*"""

        return report_template
    
    def _get_top_products(self, limit: int = 5) -> List[Dict[str, Any]]:
        """è·å–é¡¶çº§äº§å“"""
        if self.data is None or len(self.data) == 0:
            return []
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        if 'overall_score' in self.data.columns:
            top_products = self.data.nlargest(limit, 'overall_score')
        else:
            top_products = self.data.head(limit)
        
        products = []
        for _, row in top_products.iterrows():
            products.append({
                'name': row.get('product_name', 'Unknown'),
                'category': self._infer_category(row.get('product_name', '')),
                'price': row.get('price', 0),
                'impressions': row.get('impressions', 0),
                'like_rate': row.get('like_rate', 0),
                'level': row.get('recommendation_level', 'C'),
                'highlight': self._generate_product_highlight(row)
            })
        
        return products
    
    def _format_top_products(self, products: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–é¡¶çº§äº§å“å±•ç¤º"""
        if not products:
            return "æš‚æ— å‘ç°æ½œåŠ›äº§å“"
        
        formatted = []
        for i, product in enumerate(products, 1):
            formatted.append(f"""#### {i}. {product['name']}
- **ç±»åˆ«ï¼š** {product['category']}
- **ä»·æ ¼ï¼š** ${product['price']:.2f}
- **å…³é”®æŒ‡æ ‡ï¼š** å±•ç¤ºé‡{product['impressions']:,}ï¼Œç‚¹èµç‡{product['like_rate']:.1f}%
- **äº®ç‚¹ï¼š** {product['highlight']}
- **æ¨èç­‰çº§ï¼š** {product['level']}""")
        
        return '\n\n'.join(formatted)
    
    def _infer_category(self, product_name: str) -> str:
        """æ¨æ–­äº§å“ç±»åˆ«"""
        name_lower = product_name.lower()
        
        if any(word in name_lower for word in ['serum', 'cream', 'cleanser', 'toner', 'essence']):
            return 'æŠ¤è‚¤å“'
        elif any(word in name_lower for word in ['lipstick', 'foundation', 'mascara', 'eyeshadow']):
            return 'å½©å¦†'
        elif any(word in name_lower for word in ['shampoo', 'conditioner', 'hair']):
            return 'æŠ¤å‘äº§å“'
        elif any(word in name_lower for word in ['tool', 'device', 'brush', 'roller']):
            return 'ç¾å®¹å·¥å…·'
        else:
            return 'å…¶ä»–'
    
    def _generate_product_highlight(self, row: pd.Series) -> str:
        """ç”Ÿæˆäº§å“äº®ç‚¹"""
        highlights = []
        
        if row.get('like_rate', 0) > IDEAL_CRITERIA['ideal_like_rate']:
            highlights.append('é«˜å‚ä¸ç‡')
        
        if row.get('impressions', 0) > IDEAL_CRITERIA['ideal_impressions']:
            highlights.append('ç—…æ¯’ä¼ æ’­')
        
        if row.get('running_days', 0) > IDEAL_CRITERIA['ideal_running_days']:
            highlights.append('æŒç»­çƒ­åº¦')
        
        if not highlights:
            highlights.append('æ½œåŠ›äº§å“')
        
        return 'ã€'.join(highlights)
    
    def _format_watchlist_products(self) -> str:
        """æ ¼å¼åŒ–å…³æ³¨æ¸…å•äº§å“"""
        if self.data is None or len(self.data) == 0:
            return "- æš‚æ— éœ€è¦æŒç»­å…³æ³¨çš„äº§å“"
        
        # è·å–Bçº§äº§å“ä½œä¸ºå…³æ³¨æ¸…å•
        b_level = self.data[self.data['recommendation_level'] == 'B'] if 'recommendation_level' in self.data.columns else pd.DataFrame()
        
        if len(b_level) == 0:
            return "- æš‚æ— éœ€è¦æŒç»­å…³æ³¨çš„äº§å“"
        
        watchlist = []
        for _, row in b_level.head(3).iterrows():
            reason = f"å±•ç¤ºé‡{row.get('impressions', 0):,}ï¼Œç‚¹èµç‡{row.get('like_rate', 0):.1f}%"
            watchlist.append(f"- **{row.get('product_name', 'Unknown')}** - {reason}")
        
        return '\n'.join(watchlist)
    
    def _analyze_market_trends(self) -> Dict[str, str]:
        """åˆ†æå¸‚åœºè¶‹åŠ¿"""
        trends = {}
        
        if self.data is None or len(self.data) == 0:
            return {
                'category_ranking': 'æš‚æ— æ•°æ®',
                'price_analysis': 'æš‚æ— æ•°æ®',
                'hot_keywords': 'æš‚æ— ',
                'emerging_ingredients': 'æš‚æ— ',
                'creative_trends': 'æš‚æ— ',
                'regional_preferences': 'æš‚æ— æ•°æ®'
            }
        
        # ç±»åˆ«åˆ†æ
        categories = self.data['product_name'].apply(self._infer_category)
        category_counts = categories.value_counts()
        ranking = []
        for i, (cat, count) in enumerate(category_counts.head(3).items(), 1):
            pct = (count / len(self.data)) * 100
            ranking.append(f"{i}. **{cat}** ({count}ä¸ªäº§å“, {pct:.1f}%)")
        trends['category_ranking'] = '\n'.join(ranking) if ranking else 'æš‚æ— æ•°æ®'
        
        # ä»·æ ¼åˆ†æ
        if 'price' in self.data.columns:
            price_ranges = [
                ('$0-10', (self.data['price'] <= 10).sum()),
                ('$10-30', ((self.data['price'] > 10) & (self.data['price'] <= 30)).sum()),
                ('$30-50', ((self.data['price'] > 30) & (self.data['price'] <= 50)).sum()),
                ('$50+', (self.data['price'] > 50).sum())
            ]
            price_analysis = []
            for range_name, count in price_ranges:
                pct = (count / len(self.data)) * 100 if len(self.data) > 0 else 0
                price_analysis.append(f"- **{range_name}ï¼š** {count}ä¸ªäº§å“ ({pct:.1f}%)")
            trends['price_analysis'] = '\n'.join(price_analysis)
        else:
            trends['price_analysis'] = 'æš‚æ— ä»·æ ¼æ•°æ®'
        
        # çƒ­é—¨å…³é”®è¯åˆ†æ
        keywords = self._extract_hot_keywords()
        trends['hot_keywords'] = ', '.join(keywords[:5]) if keywords else 'æš‚æ— '
        
        # å…¶ä»–è¶‹åŠ¿ï¼ˆç¤ºä¾‹ï¼‰
        trends['emerging_ingredients'] = 'ç»å°¿é…¸ã€ç»´Cã€çƒŸé…°èƒº'
        trends['creative_trends'] = 'å‰åå¯¹æ¯”ã€ç”¨æˆ·å®æµ‹ã€æ˜æ˜Ÿä»£è¨€'
        trends['regional_preferences'] = 'ç¾å›½åçˆ±æŠ¤è‚¤ï¼Œè‹±å›½æ³¨é‡å½©å¦†ï¼ŒåŠ æ‹¿å¤§å…³æ³¨å¤©ç„¶æˆåˆ†'
        
        return trends
    
    def _extract_hot_keywords(self) -> List[str]:
        """æå–çƒ­é—¨å…³é”®è¯"""
        if self.data is None or 'product_name' not in self.data.columns:
            return []
        
        keyword_counts = {}
        for name in self.data['product_name']:
            if pd.isna(name):
                continue
            words = str(name).lower().split()
            for word in words:
                if len(word) > 3:  # å¿½ç•¥çŸ­è¯
                    keyword_counts[word] = keyword_counts.get(word, 0) + 1
        
        # æ’åºå¹¶è¿”å›å‰å‡ ä¸ª
        sorted_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)
        return [k for k, v in sorted_keywords[:10]]
    
    def _summarize_alerts(self) -> str:
        """æ€»ç»“é¢„è­¦ä¿¡æ¯"""
        if not self.alerts:
            return "### ğŸŸ¢ æ— é£é™©é¢„è­¦\nä»Šæ—¥æœªå‘ç°éœ€è¦ç‰¹åˆ«å…³æ³¨çš„é£é™©ã€‚"
        
        alert_summary = []
        red_alerts = [a for a in self.alerts if a.get('level') == 'error']
        yellow_alerts = [a for a in self.alerts if a.get('level') == 'warning']
        info_alerts = [a for a in self.alerts if a.get('level') == 'info']
        
        if red_alerts:
            alert_summary.append("### ğŸ”´ çº¢è‰²é¢„è­¦")
            for alert in red_alerts:
                alert_summary.append(f"- **{alert.get('type', 'Unknown')}:** {alert.get('message', '')}")
        
        if yellow_alerts:
            alert_summary.append("### ğŸŸ¡ é»„è‰²é¢„è­¦")
            for alert in yellow_alerts:
                alert_summary.append(f"- **{alert.get('type', 'Unknown')}:** {alert.get('message', '')}")
        
        if info_alerts:
            alert_summary.append("### ğŸ”µ ä¿¡æ¯æé†’")
            for alert in info_alerts:
                alert_summary.append(f"- **{alert.get('type', 'Unknown')}:** {alert.get('message', '')}")
        
        return '\n\n'.join(alert_summary)
    
    def _analyze_competitor_dynamics(self) -> str:
        """åˆ†æç«å“åŠ¨æ€"""
        # è¿™é‡Œå¯ä»¥é›†æˆå®é™…çš„ç«å“ç›‘æ§æ•°æ®
        return """### ä¸»è¦ç«å“è¡¨ç°
| ç«å“åç§° | å˜åŒ–è¶‹åŠ¿ | ä¸»è¦åŠ¨ä½œ | å½±å“è¯„ä¼° |
|----------|----------|----------|----------|
| LEDé¢è†œä»ª | â†‘ | å¢åŠ ç½‘çº¢åˆä½œ | ä¸­ |
| ç»´Cç²¾å | â†’ | ä»·æ ¼ç¨³å®š | ä½ |
| ç»å°¿é…¸é¢è†œ | â†“ | å‡å°‘æŠ•æ”¾ | ä½ |

### å€¼å¾—å­¦ä¹ çš„åˆ›æ„ç­–ç•¥
1. **LEDé¢è†œä»ª** - å‰åå¯¹æ¯”æ•ˆæœå±•ç¤º - æé«˜è½¬åŒ–ç‡
2. **ç»´Cç²¾å** - æˆåˆ†ç§‘æ™®å†…å®¹ - å¢å¼ºä¸“ä¸šæ€§"""
    
    def _calculate_collection_success_rate(self) -> float:
        """è®¡ç®—æ•°æ®é‡‡é›†æˆåŠŸç‡"""
        # åŸºäºå®é™…é‡‡é›†æƒ…å†µè®¡ç®—
        return 0.95  # 95%æˆåŠŸç‡
    
    def _calculate_data_quality_score(self) -> float:
        """è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†"""
        if self.data is None or len(self.data) == 0:
            return 0.0
        
        # åŸºäºæ•°æ®å®Œæ•´æ€§ã€å‡†ç¡®æ€§ç­‰å› ç´ 
        score = 8.5  # ç¤ºä¾‹è¯„åˆ†
        return score
    
    def _get_processing_time(self) -> str:
        """è·å–å¤„ç†æ—¶é—´"""
        return "35åˆ†é’Ÿ"
    
    def _generate_tomorrow_tasks(self) -> str:
        """ç”Ÿæˆæ˜æ—¥ä»»åŠ¡"""
        if self.data is None or len(self.data) == 0:
            return "1. **ç»§ç»­äº§å“æ‰«æ** - æ‰©å¤§æœç´¢èŒƒå›´"
        
        tasks = []
        
        # åŸºäºAçº§äº§å“ç”Ÿæˆä»»åŠ¡
        a_level = self.data[self.data['recommendation_level'] == 'A'] if 'recommendation_level' in self.data.columns else pd.DataFrame()
        for _, row in a_level.head(3).iterrows():
            tasks.append(f"**è·Ÿè¿›éªŒè¯ï¼š** {row.get('product_name', 'Unknown')} - è¿›è¡Œæ·±åº¦å¸‚åœºéªŒè¯")
        
        # åŸºäºé¢„è­¦ç”Ÿæˆä»»åŠ¡
        for alert in self.alerts[:2]:
            if alert.get('type') == 'high_potential':
                tasks.append("**åˆ†æé«˜æ½œåŠ›äº§å“** - è¯„ä¼°å¼€å‘å¯è¡Œæ€§")
        
        if not tasks:
            tasks = ["**ç»§ç»­å¸‚åœºæ‰«æ** - å¯»æ‰¾æ–°çš„äº§å“æœºä¼š"]
        
        return '\n'.join([f"{i+1}. {task}" for i, task in enumerate(tasks)])
    
    def _get_recommended_categories(self) -> str:
        """è·å–æ¨èå…³æ³¨ç±»åˆ«"""
        if self.data is None:
            return "æŠ¤è‚¤å“"
        
        # åŸºäºæœ€æ–°è¶‹åŠ¿æ¨è
        categories = self.data['product_name'].apply(self._infer_category)
        top_category = categories.value_counts().index[0] if len(categories) > 0 else "æŠ¤è‚¤å“"
        return top_category
    
    def _get_recommended_price_range(self) -> str:
        """è·å–æ¨èä»·æ ¼åŒºé—´"""
        if self.data is None or 'price' not in self.data.columns:
            return "$10-$50"
        
        median_price = self.data['price'].median()
        if median_price < 20:
            return "$10-$30"
        elif median_price < 50:
            return "$20-$60"
        else:
            return "$30-$80"
    
    def _generate_coordination_items(self) -> str:
        """ç”Ÿæˆåè°ƒäº‹é¡¹"""
        items = []
        
        # åŸºäºAçº§äº§å“ç”Ÿæˆåè°ƒéœ€æ±‚
        if self.data is not None:
            a_level_count = len(self.data[self.data['recommendation_level'] == 'A']) if 'recommendation_level' in self.data.columns else 0
            if a_level_count > 0:
                items.append("â–¡ **éœ€è¦äº§å“å¼€å‘ç¡®è®¤ï¼š** Açº§äº§å“å¼€å‘å¯è¡Œæ€§è¯„ä¼°")
        
        # åŸºäºé¢„è­¦ç”Ÿæˆåè°ƒéœ€æ±‚
        for alert in self.alerts:
            if alert.get('level') == 'warning':
                items.append("â–¡ **éœ€è¦æŠ€æœ¯æ”¯æŒï¼š** æ•°æ®è´¨é‡é—®é¢˜è°ƒæŸ¥")
                break
        
        if not items:
            items = ["â–¡ **æ— éœ€ç‰¹æ®Šåè°ƒäº‹é¡¹**"]
        
        return '\n'.join(items)
    
    def _generate_weekly_progress(self) -> str:
        """ç”Ÿæˆå‘¨åº¦è¿›åº¦"""
        # è¿™é‡Œå¯ä»¥é›†æˆå®é™…çš„è¿›åº¦è·Ÿè¸ªæ•°æ®
        return """- **ç´¯è®¡æ‰«æäº§å“ï¼š** 210ä¸ª
- **ç´¯è®¡åˆ†æäº§å“ï¼š** 45ä¸ª  
- **ç´¯è®¡æ½œåŠ›äº§å“ï¼š** 8ä¸ª
- **å‘¨ç›®æ ‡å®Œæˆç‡ï¼š** 85%"""
    
    def _generate_monthly_progress(self) -> str:
        """ç”Ÿæˆæœˆåº¦è¿›åº¦"""
        return """- **æœˆåº¦æ‰«æç›®æ ‡ï¼š** 900ä¸ª (å®Œæˆ78%)
- **æœˆåº¦å‘ç°ç›®æ ‡ï¼š** 30ä¸ª (å®Œæˆ67%)
- **æœˆåº¦æ¨èç›®æ ‡ï¼š** 15ä¸ª (å®Œæˆ80%)"""
    
    def create_visualizations(self) -> List[str]:
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        try:
            self.logger.info("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
            
            if self.data is None or len(self.data) == 0:
                self.logger.warning("æ— æ•°æ®å¯ç”¨äºå¯è§†åŒ–")
                return []
            
            chart_files = []
            
            # 1. æ¨èç­‰çº§åˆ†å¸ƒé¥¼å›¾
            chart_files.append(self._create_recommendation_pie_chart())
            
            # 2. ä»·æ ¼åˆ†å¸ƒç›´æ–¹å›¾
            chart_files.append(self._create_price_histogram())
            
            # 3. ç‚¹èµç‡ vs å±•ç¤ºé‡æ•£ç‚¹å›¾
            chart_files.append(self._create_engagement_scatter_plot())
            
            # 4. è¶‹åŠ¿åˆ†æå›¾
            chart_files.append(self._create_trend_analysis_chart())
            
            self.logger.info(f"å·²ç”Ÿæˆ {len(chart_files)} ä¸ªå›¾è¡¨")
            return chart_files
            
        except Exception as e:
            self.logger.error(f"å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
            return []
    
    def _create_recommendation_pie_chart(self) -> str:
        """åˆ›å»ºæ¨èç­‰çº§åˆ†å¸ƒé¥¼å›¾"""
        try:
            plt.figure(figsize=(8, 6))
            
            if 'recommendation_level' in self.data.columns:
                level_counts = self.data['recommendation_level'].value_counts()
                colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']
                
                plt.pie(level_counts.values, labels=level_counts.index, autopct='%1.1f%%', 
                       colors=colors, startangle=90)
                plt.title('äº§å“æ¨èç­‰çº§åˆ†å¸ƒ', fontsize=14, fontweight='bold')
            else:
                plt.text(0.5, 0.5, 'æš‚æ— æ¨èç­‰çº§æ•°æ®', ha='center', va='center', fontsize=12)
                plt.title('äº§å“æ¨èç­‰çº§åˆ†å¸ƒ', fontsize=14, fontweight='bold')
            
            plt.axis('equal')
            
            chart_file = os.path.join(self.charts_dir, f'recommendation_distribution_{datetime.now().strftime("%Y%m%d")}.png')
            plt.savefig(chart_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            return chart_file
            
        except Exception as e:
            self.logger.error(f"æ¨èç­‰çº§é¥¼å›¾ç”Ÿæˆå¤±è´¥: {e}")
            return ""
    
    def _create_price_histogram(self) -> str:
        """åˆ›å»ºä»·æ ¼åˆ†å¸ƒç›´æ–¹å›¾"""
        try:
            plt.figure(figsize=(10, 6))
            
            if 'price' in self.data.columns:
                plt.hist(self.data['price'], bins=20, color='skyblue', alpha=0.7, edgecolor='black')
                plt.xlabel('ä»·æ ¼ ($)')
                plt.ylabel('äº§å“æ•°é‡')
                plt.title('äº§å“ä»·æ ¼åˆ†å¸ƒ', fontsize=14, fontweight='bold')
                plt.grid(True, alpha=0.3)
                
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                mean_price = self.data['price'].mean()
                median_price = self.data['price'].median()
                plt.axvline(mean_price, color='red', linestyle='--', label=f'å¹³å‡ä»·æ ¼: ${mean_price:.2f}')
                plt.axvline(median_price, color='green', linestyle='--', label=f'ä¸­ä½æ•°ä»·æ ¼: ${median_price:.2f}')
                plt.legend()
            else:
                plt.text(0.5, 0.5, 'æš‚æ— ä»·æ ¼æ•°æ®', ha='center', va='center', fontsize=12)
                plt.title('äº§å“ä»·æ ¼åˆ†å¸ƒ', fontsize=14, fontweight='bold')
            
            chart_file = os.path.join(self.charts_dir, f'price_distribution_{datetime.now().strftime("%Y%m%d")}.png')
            plt.savefig(chart_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            return chart_file
            
        except Exception as e:
            self.logger.error(f"ä»·æ ¼åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")
            return ""
    
    def _create_engagement_scatter_plot(self) -> str:
        """åˆ›å»ºå‚ä¸ç‡æ•£ç‚¹å›¾"""
        try:
            plt.figure(figsize=(10, 6))
            
            if 'like_rate' in self.data.columns and 'impressions' in self.data.columns:
                # æŒ‰æ¨èç­‰çº§ç€è‰²
                colors = {'A': 'red', 'B': 'orange', 'C': 'yellow', 'D': 'gray'}
                
                for level in ['A', 'B', 'C', 'D']:
                    level_data = self.data[self.data['recommendation_level'] == level] if 'recommendation_level' in self.data.columns else pd.DataFrame()
                    if len(level_data) > 0:
                        plt.scatter(level_data['impressions'], level_data['like_rate'], 
                                  c=colors.get(level, 'gray'), label=f'{level}çº§äº§å“', alpha=0.7)
                
                plt.xlabel('å±•ç¤ºé‡')
                plt.ylabel('ç‚¹èµç‡ (%)')
                plt.title('äº§å“å‚ä¸åº¦åˆ†æ', fontsize=14, fontweight='bold')
                plt.xscale('log')  # å¯¹æ•°åæ ‡
                plt.grid(True, alpha=0.3)
                plt.legend()
                
                # æ·»åŠ åŸºå‡†çº¿
                plt.axhline(y=HARD_CRITERIA['min_like_rate'], color='red', linestyle='--', 
                           label=f'æœ€ä½æ ‡å‡†: {HARD_CRITERIA["min_like_rate"]}%')
                plt.axhline(y=IDEAL_CRITERIA['ideal_like_rate'], color='green', linestyle='--', 
                           label=f'ç†æƒ³æ ‡å‡†: {IDEAL_CRITERIA["ideal_like_rate"]}%')
            else:
                plt.text(0.5, 0.5, 'æš‚æ— å‚ä¸åº¦æ•°æ®', ha='center', va='center', fontsize=12)
                plt.title('äº§å“å‚ä¸åº¦åˆ†æ', fontsize=14, fontweight='bold')
            
            chart_file = os.path.join(self.charts_dir, f'engagement_analysis_{datetime.now().strftime("%Y%m%d")}.png')
            plt.savefig(chart_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            return chart_file
            
        except Exception as e:
            self.logger.error(f"å‚ä¸åº¦æ•£ç‚¹å›¾ç”Ÿæˆå¤±è´¥: {e}")
            return ""
    
    def _create_trend_analysis_chart(self) -> str:
        """åˆ›å»ºè¶‹åŠ¿åˆ†æå›¾"""
        try:
            plt.figure(figsize=(12, 8))
            
            # åˆ›å»º2x2çš„å­å›¾
            fig, axes = plt.subplots(2, 2, figsize=(12, 8))
            fig.suptitle('å¸‚åœºè¶‹åŠ¿åˆ†æ', fontsize=16, fontweight='bold')
            
            # 1. ç±»åˆ«åˆ†å¸ƒ
            categories = self.data['product_name'].apply(self._infer_category)
            category_counts = categories.value_counts()
            axes[0, 0].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')
            axes[0, 0].set_title('äº§å“ç±»åˆ«åˆ†å¸ƒ')
            
            # 2. è¿è¡Œå¤©æ•°åˆ†å¸ƒ
            if 'running_days' in self.data.columns:
                axes[0, 1].hist(self.data['running_days'], bins=15, color='lightcoral', alpha=0.7)
                axes[0, 1].set_title('äº§å“è¿è¡Œå¤©æ•°åˆ†å¸ƒ')
                axes[0, 1].set_xlabel('è¿è¡Œå¤©æ•°')
                axes[0, 1].set_ylabel('äº§å“æ•°é‡')
            
            # 3. ä»·æ ¼vsç‚¹èµç‡
            if 'price' in self.data.columns and 'like_rate' in self.data.columns:
                axes[1, 0].scatter(self.data['price'], self.data['like_rate'], alpha=0.6)
                axes[1, 0].set_title('ä»·æ ¼ä¸ç‚¹èµç‡å…³ç³»')
                axes[1, 0].set_xlabel('ä»·æ ¼ ($)')
                axes[1, 0].set_ylabel('ç‚¹èµç‡ (%)')
            
            # 4. å±•ç¤ºé‡åˆ†çº§ç»Ÿè®¡
            if 'impressions' in self.data.columns:
                impression_ranges = pd.cut(self.data['impressions'], 
                                         bins=[0, 1000, 5000, 10000, float('inf')], 
                                         labels=['<1K', '1K-5K', '5K-10K', '>10K'])
                range_counts = impression_ranges.value_counts()
                axes[1, 1].bar(range_counts.index, range_counts.values, color='lightgreen')
                axes[1, 1].set_title('å±•ç¤ºé‡åˆ†çº§ç»Ÿè®¡')
                axes[1, 1].set_xlabel('å±•ç¤ºé‡èŒƒå›´')
                axes[1, 1].set_ylabel('äº§å“æ•°é‡')
            
            plt.tight_layout()
            
            chart_file = os.path.join(self.charts_dir, f'trend_analysis_{datetime.now().strftime("%Y%m%d")}.png')
            plt.savefig(chart_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            return chart_file
            
        except Exception as e:
            self.logger.error(f"è¶‹åŠ¿åˆ†æå›¾ç”Ÿæˆå¤±è´¥: {e}")
            return ""
    
    def update_excel_database(self) -> bool:
        """æ›´æ–°Excelæ•°æ®åº“"""
        try:
            self.logger.info("æ›´æ–°Excelæ•°æ®åº“...")
            
            if self.data is None or len(self.data) == 0:
                self.logger.warning("æ— æ•°æ®å¯æ›´æ–°åˆ°Excel")
                return False
            
            excel_file = PATHS['excel_database']
            
            # å‡†å¤‡æ•°æ®
            today_str = datetime.now().strftime('%Y-%m-%d')
            self.data['update_date'] = today_str
            
            if os.path.exists(excel_file):
                # æ›´æ–°ç°æœ‰æ–‡ä»¶
                with pd.ExcelWriter(excel_file, mode='a', if_sheet_exists='replace', engine='openpyxl') as writer:
                    # æ¯æ—¥æ‰«æè®°å½•
                    self.data.to_excel(writer, sheet_name=EXCEL_SHEETS['daily_scan'], index=False)
                    
                    # ç”Ÿæˆæ±‡æ€»æ•°æ®
                    summary_data = self._generate_summary_data()
                    summary_data.to_excel(writer, sheet_name=EXCEL_SHEETS['weekly_summary'], index=False)
                    
                    # é¢„è­¦è®°å½•
                    if self.alerts:
                        alerts_df = pd.DataFrame(self.alerts)
                        alerts_df.to_excel(writer, sheet_name=EXCEL_SHEETS['alerts'], index=False)
            else:
                # åˆ›å»ºæ–°æ–‡ä»¶
                with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                    self.data.to_excel(writer, sheet_name=EXCEL_SHEETS['daily_scan'], index=False)
                    
                    summary_data = self._generate_summary_data()
                    summary_data.to_excel(writer, sheet_name=EXCEL_SHEETS['weekly_summary'], index=False)
                    
                    if self.alerts:
                        alerts_df = pd.DataFrame(self.alerts)
                        alerts_df.to_excel(writer, sheet_name=EXCEL_SHEETS['alerts'], index=False)
            
            self.logger.info(f"Excelæ•°æ®åº“å·²æ›´æ–°: {excel_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"Excelæ•°æ®åº“æ›´æ–°å¤±è´¥: {e}")
            return False
    
    def _generate_summary_data(self) -> pd.DataFrame:
        """ç”Ÿæˆæ±‡æ€»æ•°æ®"""
        try:
            summary = {
                'date': [datetime.now().strftime('%Y-%m-%d')],
                'total_products': [len(self.data)],
                'a_level_products': [len(self.data[self.data['recommendation_level'] == 'A']) if 'recommendation_level' in self.data.columns else 0],
                'b_level_products': [len(self.data[self.data['recommendation_level'] == 'B']) if 'recommendation_level' in self.data.columns else 0],
                'high_potential_products': [len(self.data[self.data['high_potential'] == True]) if 'high_potential' in self.data.columns else 0],
                'average_like_rate': [self.data['like_rate'].mean() if 'like_rate' in self.data.columns else 0],
                'average_price': [self.data['price'].mean() if 'price' in self.data.columns else 0],
                'alerts_count': [len(self.alerts)]
            }
            
            return pd.DataFrame(summary)
            
        except Exception as e:
            self.logger.error(f"æ±‡æ€»æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
            return pd.DataFrame()
    
    def send_notifications(self) -> bool:
        """å‘é€é€šçŸ¥å’Œé¢„è­¦"""
        try:
            if not NOTIFICATION_CONFIG['file_log_enabled']:
                return True
            
            # ç”Ÿæˆé€šçŸ¥æ–‡ä»¶
            notification_file = get_output_path('./outputs/notifications_{date}.json')
            
            notifications = {
                'timestamp': datetime.now().isoformat(),
                'alerts': self.alerts,
                'summary': self.analysis_results,
                'urgent_items': self._get_urgent_items()
            }
            
            with open(notification_file, 'w', encoding='utf-8') as f:
                json.dump(notifications, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"é€šçŸ¥å·²ç”Ÿæˆ: {notification_file}")
            
            # æ§åˆ¶å°è¾“å‡ºé‡è¦é€šçŸ¥
            if NOTIFICATION_CONFIG['console_log_enabled']:
                urgent_alerts = [a for a in self.alerts if a.get('level') in ['error', 'warning']]
                if urgent_alerts:
                    print("\nğŸš¨ é‡è¦é€šçŸ¥:")
                    for alert in urgent_alerts:
                        print(f"  - {alert.get('message', '')}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"é€šçŸ¥å‘é€å¤±è´¥: {e}")
            return False
    
    def _get_urgent_items(self) -> List[Dict[str, Any]]:
        """è·å–ç´§æ€¥äº‹é¡¹"""
        urgent_items = []
        
        # Açº§äº§å“éœ€è¦ç«‹å³å…³æ³¨
        if self.data is not None:
            a_level_products = self.data[self.data['recommendation_level'] == 'A'] if 'recommendation_level' in self.data.columns else pd.DataFrame()
            for _, row in a_level_products.iterrows():
                urgent_items.append({
                    'type': 'high_priority_product',
                    'message': f"Açº§äº§å“éœ€è¦éªŒè¯: {row.get('product_name', 'Unknown')}",
                    'priority': 'high'
                })
        
        # ä¸¥é‡é¢„è­¦
        for alert in self.alerts:
            if alert.get('level') == 'error':
                urgent_items.append({
                    'type': 'critical_alert',
                    'message': alert.get('message', ''),
                    'priority': 'critical'
                })
        
        return urgent_items
    
    def generate_full_report(self, data_file: str, analysis_results: Dict[str, Any] = None, alerts: List[Dict] = None) -> Dict[str, str]:
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        try:
            self.logger.info("=== å¼€å§‹ç”Ÿæˆå®Œæ•´æŠ¥å‘Š ===")
            
            # åŠ è½½æ•°æ®
            if not self.load_data(data_file, analysis_results, alerts):
                return {}
            
            # ç”Ÿæˆå„ç±»æŠ¥å‘Š
            report_files = {}
            
            # 1. æ¯æ—¥ç®€æŠ¥
            daily_report = self.generate_daily_report()
            if daily_report:
                report_files['daily_report'] = daily_report
            
            # 2. å¯è§†åŒ–å›¾è¡¨
            chart_files = self.create_visualizations()
            if chart_files:
                report_files['charts'] = chart_files
            
            # 3. Excelæ•°æ®åº“æ›´æ–°
            if self.update_excel_database():
                report_files['excel_database'] = PATHS['excel_database']
            
            # 4. é€šçŸ¥å’Œé¢„è­¦
            if self.send_notifications():
                report_files['notifications'] = get_output_path('./outputs/notifications_{date}.json')
            
            self.logger.info(f"=== æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(report_files)} ç±»æ–‡ä»¶ ===")
            return report_files
            
        except Exception as e:
            self.logger.error(f"å®Œæ•´æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return {}

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    generator = ReportGenerator()
    
    # ç¤ºä¾‹æ•°æ®
    sample_data = pd.DataFrame({
        'product_name': ['ç»´Cç²¾åæ¶²', 'LEDé¢è†œ', 'ç»å°¿é…¸é¢è†œ', 'èƒ¶åŸè›‹ç™½'],
        'impressions': [15000, 25000, 8000, 12000],
        'likes': [450, 750, 200, 360],
        'comments': [89, 156, 45, 72],
        'price': [29.99, 89.99, 19.99, 39.99],
        'running_days': [14, 21, 7, 18],
        'like_rate': [3.0, 3.0, 2.5, 3.0],
        'recommendation_level': ['A', 'A', 'B', 'B'],
        'high_potential': [True, True, False, False],
        'overall_score': [85, 90, 65, 70]
    })
    
    sample_analysis = {
        'total_products': 4,
        'high_potential_count': 2,
        'alerts_count': 1
    }
    
    sample_alerts = [{
        'type': 'high_potential',
        'level': 'info',
        'message': 'å‘ç°2ä¸ªé«˜æ½œåŠ›äº§å“',
        'timestamp': datetime.now().isoformat()
    }]
    
    # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    report_files = generator.generate_full_report(sample_data, sample_analysis, sample_alerts)
    
    print("æŠ¥å‘Šç”Ÿæˆå®Œæˆ:")
    for report_type, file_path in report_files.items():
        print(f"  {report_type}: {file_path}")