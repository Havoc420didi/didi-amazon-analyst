# Pipiads RPAç³»ç»Ÿéƒ¨ç½²å’Œç»´æŠ¤æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [ç³»ç»Ÿæ¦‚è§ˆ](#ç³»ç»Ÿæ¦‚è§ˆ)
2. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
3. [å®‰è£…éƒ¨ç½²](#å®‰è£…éƒ¨ç½²)
4. [é…ç½®ç®¡ç†](#é…ç½®ç®¡ç†)
5. [è¿è¡Œç›‘æ§](#è¿è¡Œç›‘æ§)
6. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
7. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
8. [å®‰å…¨ç®¡ç†](#å®‰å…¨ç®¡ç†)
9. [å¤‡ä»½æ¢å¤](#å¤‡ä»½æ¢å¤)
10. [å‡çº§ç»´æŠ¤](#å‡çº§ç»´æŠ¤)

---

## ç³»ç»Ÿæ¦‚è§ˆ

### æ¶æ„ç»„ä»¶
Pipiads RPAç³»ç»Ÿç”±ä»¥ä¸‹æ ¸å¿ƒæ¨¡å—ç»„æˆï¼š

- **æ•°æ®é‡‡é›†æ¨¡å—** (`data_collector.py`) - è‡ªåŠ¨åŒ–Pipiadsæ•°æ®æŠ“å–
- **æ•°æ®å¤„ç†æ¨¡å—** (`data_processor.py`) - æ•°æ®æ¸…æ´—ã€åˆ†æå’Œåˆ†çº§
- **æŠ¥å‘Šç”Ÿæˆæ¨¡å—** (`report_generator.py`) - è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Šå’Œå¯è§†åŒ–
- **äººæœºåä½œæ¨¡å—** (`human_collaboration.py`) - ç®¡ç†äººå·¥å®¡æ ¸æµç¨‹
- **é…ç½®ç®¡ç†** (`config.py`) - ç³»ç»Ÿé…ç½®å’Œå‚æ•°ç®¡ç†

### æŠ€æœ¯æ ˆ
- **ç¼–ç¨‹è¯­è¨€ï¼š** Python 3.8+
- **Webè‡ªåŠ¨åŒ–ï¼š** Selenium WebDriver
- **æ•°æ®å¤„ç†ï¼š** pandas, numpy, scipy
- **å¯è§†åŒ–ï¼š** matplotlib, seaborn
- **æ•°æ®åº“ï¼š** SQLite
- **ä»»åŠ¡è°ƒåº¦ï¼š** APScheduler
- **æ—¥å¿—ç®¡ç†ï¼š** Python logging

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿï¼š** Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **å†…å­˜ï¼š** 8GB+ RAM
- **å­˜å‚¨ï¼š** 50GB+ å¯ç”¨ç©ºé—´
- **ç½‘ç»œï¼š** ç¨³å®šçš„äº’è”ç½‘è¿æ¥
- **æµè§ˆå™¨ï¼š** Chrome 90+ (è‡ªåŠ¨ä¸‹è½½ChromeDriver)

---

## ç¯å¢ƒå‡†å¤‡

### 1. Pythonç¯å¢ƒå®‰è£…

#### Windows
```bash
# ä¸‹è½½å¹¶å®‰è£…Python 3.8+
# https://www.python.org/downloads/

# éªŒè¯å®‰è£…
python --version
pip --version
```

#### macOS
```bash
# ä½¿ç”¨Homebrewå®‰è£…
brew install python@3.9

# æˆ–ä½¿ç”¨pyenv
pyenv install 3.9.16
pyenv global 3.9.16
```

#### Ubuntu
```bash
sudo apt update
sudo apt install python3.9 python3.9-pip python3.9-venv
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv pipiads_rpa_env

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows
pipiads_rpa_env\Scripts\activate

# macOS/Linux
source pipiads_rpa_env/bin/activate
```

### 3. å®‰è£…ä¾èµ–åŒ…
```bash
pip install -r requirements.txt
```

#### requirements.txt
```text
selenium==4.15.0
pandas==2.0.3
numpy==1.24.3
matplotlib==3.7.2
seaborn==0.12.2
scipy==1.11.2
beautifulsoup4==4.12.2
requests==2.31.0
APScheduler==3.10.4
openpyxl==3.1.2
lxml==4.9.3
Pillow==10.0.0
```

### 4. ç³»ç»Ÿä¾èµ–å®‰è£…

#### Chromeæµè§ˆå™¨
```bash
# Windows: è®¿é—® https://www.google.com/chrome/ ä¸‹è½½å®‰è£…

# macOS
brew install --cask google-chrome

# Ubuntu
wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
sudo apt update
sudo apt install google-chrome-stable
```

#### å¯é€‰ï¼šä»£ç†å·¥å…·
å¦‚æœéœ€è¦ä½¿ç”¨ä»£ç†ï¼Œå®‰è£…ç›¸åº”çš„ä»£ç†å®¢æˆ·ç«¯ã€‚

---

## å®‰è£…éƒ¨ç½²

### 1. é¡¹ç›®éƒ¨ç½²

#### ä¸‹è½½é¡¹ç›®ä»£ç 
```bash
# å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®ä»£ç åˆ°æŒ‡å®šç›®å½•
cd /opt/pipiads_rpa  # Linux/macOS
cd C:\pipiads_rpa    # Windows

# å¤åˆ¶æ‰€æœ‰RPAæ¨¡å—æ–‡ä»¶
# - config.py
# - data_collector.py
# - data_processor.py
# - report_generator.py
# - human_collaboration.py
# - main.py (ä¸»å¯åŠ¨è„šæœ¬)
```

#### åˆ›å»ºç›®å½•ç»“æ„
```bash
mkdir -p outputs/charts
mkdir -p logs
mkdir -p downloads
mkdir -p backups
```

### 2. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š
```bash
# Pipiadsè´¦æˆ·é…ç½®
PIPIADS_USERNAME=your_username
PIPIADS_PASSWORD=your_password

# ä»£ç†é…ç½®ï¼ˆå¯é€‰ï¼‰
PROXY_URL=http://proxy.example.com:8080

# ç”¨æˆ·ä»£ç†
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36

# é€šçŸ¥é…ç½®ï¼ˆå¯é€‰ï¼‰
NOTIFICATION_EMAIL=admin@company.com
SLACK_WEBHOOK=https://hooks.slack.com/services/xxx
```

### 3. é…ç½®æ–‡ä»¶éªŒè¯
```bash
python -c "from config import validate_config; validate_config()"
```

### 4. åˆå§‹åŒ–æµ‹è¯•
```bash
# æµ‹è¯•æ•°æ®é‡‡é›†æ¨¡å—
python data_collector.py

# æµ‹è¯•æ•°æ®å¤„ç†æ¨¡å—
python data_processor.py

# æµ‹è¯•æŠ¥å‘Šç”Ÿæˆæ¨¡å—
python report_generator.py
```

---

## é…ç½®ç®¡ç†

### 1. åŸºç¡€é…ç½®è°ƒæ•´

#### ä¿®æ”¹ `config.py` ä¸­çš„å…³é”®å‚æ•°ï¼š

```python
# è°ƒæ•´ç­›é€‰æ¡ä»¶
HARD_CRITERIA = {
    'min_impressions': 1000,      # æ ¹æ®éœ€è¦è°ƒæ•´æœ€ä½å±•ç¤ºé‡
    'min_likes': 200,            # è°ƒæ•´æœ€ä½ç‚¹èµæ•°
    'min_like_rate': 2.5,        # è°ƒæ•´æœ€ä½ç‚¹èµç‡
    'min_running_days': 10,      # è°ƒæ•´æœ€ä½è¿è¡Œå¤©æ•°
    'min_comments': 30           # è°ƒæ•´æœ€ä½è¯„è®ºæ•°
}

# è°ƒæ•´ä»·æ ¼èŒƒå›´
FILTER_CONFIG['price_range'] = {
    'min': 5,    # æœ€ä½ä»·æ ¼
    'max': 200   # æœ€é«˜ä»·æ ¼
}

# è°ƒæ•´é‡‡é›†é¢‘ç‡
SCHEDULE_CONFIG = {
    'daily_scan_time': '09:00',           # æ¯æ—¥æ‰«ææ—¶é—´
    'competitor_monitor_time': '13:00',   # ç«å“ç›‘æ§æ—¶é—´
    'daily_report_time': '18:00'         # æ¯æ—¥æŠ¥å‘Šæ—¶é—´
}
```

### 2. æµè§ˆå™¨é…ç½®ä¼˜åŒ–

```python
# é’ˆå¯¹ä¸åŒç¯å¢ƒä¼˜åŒ–æµè§ˆå™¨é…ç½®
BROWSER_CONFIG = {
    'headless': True,              # ç”Ÿäº§ç¯å¢ƒå»ºè®®è®¾ä¸ºTrue
    'window_width': 1920,
    'window_height': 1080,
    'page_load_timeout': 60,       # å¢åŠ è¶…æ—¶æ—¶é—´
    'implicit_wait': 15,
    'download_dir': './downloads'
}
```

### 3. æ•°æ®è´¨é‡é…ç½®

```python
# è°ƒæ•´å¼‚å¸¸æ£€æµ‹æ•æ„Ÿåº¦
ANOMALY_DETECTION = {
    'z_score_threshold': 2.5,    # é™ä½é˜ˆå€¼å¢åŠ æ•æ„Ÿåº¦
    'iqr_multiplier': 1.2,       # è°ƒæ•´IQRå€æ•°
    'enable_outlier_removal': True
}

# è°ƒæ•´é¢„è­¦é˜ˆå€¼
ALERT_THRESHOLDS = {
    'high_potential_impressions': 15000,   # é«˜æ½œåŠ›äº§å“å±•ç¤ºé‡é˜ˆå€¼
    'high_potential_like_rate': 3.5,      # é«˜æ½œåŠ›äº§å“ç‚¹èµç‡é˜ˆå€¼
    'data_quality_threshold': 0.90        # æ•°æ®è´¨é‡é˜ˆå€¼
}
```

---

## è¿è¡Œç›‘æ§

### 1. åˆ›å»ºä¸»å¯åŠ¨è„šæœ¬

åˆ›å»º `main.py`ï¼š
```python
#!/usr/bin/env python
"""
Pipiads RPAç³»ç»Ÿä¸»å¯åŠ¨è„šæœ¬
"""

import schedule
import time
import logging
from datetime import datetime
from data_collector import PipiadsCollector
from data_processor import DataProcessor
from report_generator import ReportGenerator
from human_collaboration import HumanCollaborationManager
from config import *

class PipiadsRPASystem:
    def __init__(self):
        self.logger = self._setup_logger()
        self.collector = PipiadsCollector()
        self.processor = DataProcessor()
        self.reporter = ReportGenerator()
        self.collaboration = HumanCollaborationManager()
        
    def _setup_logger(self):
        logger = logging.getLogger('PipiadsRPA')
        logger.setLevel(logging.INFO)
        
        handler = logging.FileHandler(
            get_output_path(PATHS['activity_log']), 
            encoding='utf-8'
        )
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def daily_workflow(self):
        """æ¯æ—¥å·¥ä½œæµç¨‹"""
        try:
            self.logger.info("=== å¼€å§‹æ¯æ—¥å·¥ä½œæµç¨‹ ===")
            
            # 1. æ•°æ®é‡‡é›†
            if not self.collector.start_session():
                raise Exception("é‡‡é›†ä¼šè¯å¯åŠ¨å¤±è´¥")
            
            if not self.collector.login():
                raise Exception("ç™»å½•å¤±è´¥")
            
            if not self.collector.setup_search_filters():
                raise Exception("ç­›é€‰å™¨è®¾ç½®å¤±è´¥")
            
            today_keywords = get_today_keywords()
            if not self.collector.search_products(today_keywords):
                raise Exception("äº§å“æœç´¢å¤±è´¥")
            
            # ä¿å­˜é‡‡é›†æ•°æ®
            if not self.collector.save_data():
                raise Exception("æ•°æ®ä¿å­˜å¤±è´¥")
            
            data_file = get_output_path(PATHS['daily_scan_file'])
            
            # 2. æ•°æ®å¤„ç†
            analysis_results = self.processor.process_data(data_file)
            if not analysis_results:
                raise Exception("æ•°æ®å¤„ç†å¤±è´¥")
            
            # 3. ç”ŸæˆæŠ¥å‘Š
            report_files = self.reporter.generate_full_report(
                self.processor.processed_data, 
                analysis_results, 
                self.processor.alerts
            )
            
            # 4. æ£€æŸ¥äººå·¥å®¡æ ¸é˜Ÿåˆ—
            self.collaboration.run_maintenance_tasks()
            
            self.logger.info("=== æ¯æ—¥å·¥ä½œæµç¨‹å®Œæˆ ===")
            
        except Exception as e:
            self.logger.error(f"æ¯æ—¥å·¥ä½œæµç¨‹å¤±è´¥: {e}")
        finally:
            self.collector.close_session()
    
    def competitor_monitoring(self):
        """ç«å“ç›‘æ§"""
        try:
            self.logger.info("å¼€å§‹ç«å“ç›‘æ§...")
            # å®ç°ç«å“ç›‘æ§é€»è¾‘
            
        except Exception as e:
            self.logger.error(f"ç«å“ç›‘æ§å¤±è´¥: {e}")
    
    def start_scheduler(self):
        """å¯åŠ¨ä»»åŠ¡è°ƒåº¦å™¨"""
        # å®‰æ’æ¯æ—¥ä»»åŠ¡
        schedule.every().day.at(SCHEDULE_CONFIG['daily_scan_time']).do(self.daily_workflow)
        schedule.every().day.at(SCHEDULE_CONFIG['competitor_monitor_time']).do(self.competitor_monitoring)
        
        # å®‰æ’ç»´æŠ¤ä»»åŠ¡
        schedule.every().hour.do(self.collaboration.check_overdue_items)
        schedule.every().day.at("23:00").do(self.collaboration.run_maintenance_tasks)
        
        self.logger.info("ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
        
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

if __name__ == "__main__":
    rpa_system = PipiadsRPASystem()
    rpa_system.start_scheduler()
```

### 2. åˆ›å»ºæœåŠ¡è„šæœ¬

#### LinuxæœåŠ¡ (systemd)
åˆ›å»º `/etc/systemd/system/pipiads-rpa.service`ï¼š
```ini
[Unit]
Description=Pipiads RPA System
After=network.target

[Service]
Type=simple
User=rpa_user
WorkingDirectory=/opt/pipiads_rpa
Environment=PATH=/opt/pipiads_rpa/pipiads_rpa_env/bin
ExecStart=/opt/pipiads_rpa/pipiads_rpa_env/bin/python main.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨æœåŠ¡ï¼š
```bash
sudo systemctl daemon-reload
sudo systemctl enable pipiads-rpa
sudo systemctl start pipiads-rpa
sudo systemctl status pipiads-rpa
```

#### WindowsæœåŠ¡
ä½¿ç”¨ `python-windows-service` åŒ…ï¼š
```bash
pip install pywin32
python setup_service.py install
python setup_service.py start
```

### 3. ç›‘æ§è„šæœ¬

åˆ›å»º `monitor.py`ï¼š
```python
#!/usr/bin/env python
"""
RPAç³»ç»Ÿç›‘æ§è„šæœ¬
"""

import os
import psutil
import json
from datetime import datetime
from pathlib import Path

def check_system_health():
    """æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€"""
    health_status = {
        'timestamp': datetime.now().isoformat(),
        'cpu_usage': psutil.cpu_percent(interval=1),
        'memory_usage': psutil.virtual_memory().percent,
        'disk_usage': psutil.disk_usage('/').percent,
        'processes': []
    }
    
    # æ£€æŸ¥RPAè¿›ç¨‹
    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
        try:
            if 'main.py' in ' '.join(proc.info['cmdline']):
                health_status['processes'].append({
                    'pid': proc.info['pid'],
                    'name': proc.info['name'],
                    'status': proc.status(),
                    'cpu_percent': proc.cpu_percent(),
                    'memory_percent': proc.memory_percent()
                })
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue
    
    # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
    log_file = Path('logs/activity_' + datetime.now().strftime('%Y%m%d') + '.log')
    if log_file.exists():
        health_status['log_file_size'] = log_file.stat().st_size
        health_status['log_last_modified'] = datetime.fromtimestamp(
            log_file.stat().st_mtime
        ).isoformat()
    
    return health_status

if __name__ == "__main__":
    health = check_system_health()
    print(json.dumps(health, indent=2, ensure_ascii=False))
```

### 4. æ—¥å¿—ç›‘æ§

åˆ›å»ºæ—¥å¿—è½®è½¬é…ç½® `/etc/logrotate.d/pipiads-rpa`ï¼š
```
/opt/pipiads_rpa/logs/*.log {
    daily
    missingok
    rotate 30
    compress
    notifempty
    create 0644 rpa_user rpa_group
}
```

---

## æ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜è¯Šæ–­

#### æ•°æ®é‡‡é›†å¤±è´¥
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping www.pipiads.com

# æ£€æŸ¥æµè§ˆå™¨ç‰ˆæœ¬
google-chrome --version

# æ£€æŸ¥ChromeDriverç‰ˆæœ¬
chromedriver --version

# æµ‹è¯•ç™»å½•
python -c "
from data_collector import PipiadsCollector
collector = PipiadsCollector()
collector.start_session()
print('ç™»å½•ç»“æœ:', collector.login())
collector.close_session()
"
```

#### æ•°æ®å¤„ç†é”™è¯¯
```bash
# æ£€æŸ¥æ•°æ®æ–‡ä»¶
ls -la outputs/daily_scan_*.csv

# éªŒè¯æ•°æ®æ ¼å¼
python -c "
import pandas as pd
df = pd.read_csv('outputs/daily_scan_$(date +%Y%m%d).csv')
print('æ•°æ®å½¢çŠ¶:', df.shape)
print('åˆ—å:', df.columns.tolist())
print('æ•°æ®ç±»å‹:', df.dtypes)
"
```

#### å†…å­˜ä¸è¶³
```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h  # Linux
vm_stat # macOS

# ä¼˜åŒ–é…ç½®
# åœ¨config.pyä¸­å‡å°‘å¹¶å‘å¤„ç†æ•°é‡
# å¯ç”¨æ•°æ®åˆ†æ‰¹å¤„ç†
```

### 2. é”™è¯¯æ—¥å¿—åˆ†æ

#### æ—¥å¿—çº§åˆ«é…ç½®
```python
# åœ¨config.pyä¸­è°ƒæ•´æ—¥å¿—çº§åˆ«
logging.basicConfig(
    level=logging.DEBUG,  # è¯¦ç»†è°ƒè¯•ä¿¡æ¯
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

#### å¸¸è§é”™è¯¯ç 
- **ç™»å½•å¤±è´¥ (AUTH_ERROR)**: æ£€æŸ¥ç”¨æˆ·åå¯†ç 
- **ç½‘ç»œè¶…æ—¶ (NETWORK_TIMEOUT)**: æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å¢åŠ è¶…æ—¶æ—¶é—´
- **å…ƒç´ æœªæ‰¾åˆ° (ELEMENT_NOT_FOUND)**: ç½‘ç«™ç»“æ„å¯èƒ½å·²æ›´æ”¹
- **æ•°æ®æ ¼å¼é”™è¯¯ (DATA_FORMAT_ERROR)**: æ£€æŸ¥æ•°æ®éªŒè¯è§„åˆ™

### 3. ç´§æ€¥æ¢å¤æµç¨‹

#### ç³»ç»Ÿå´©æºƒæ¢å¤
```bash
# 1. åœæ­¢æœåŠ¡
sudo systemctl stop pipiads-rpa

# 2. æ£€æŸ¥æŸåçš„æ–‡ä»¶
find outputs/ -name "*.csv" -size 0 -delete

# 3. æ¢å¤æœ€è¿‘çš„å¤‡ä»½
cp backups/latest/* outputs/

# 4. é‡å¯æœåŠ¡
sudo systemctl start pipiads-rpa
```

#### æ•°æ®åº“æ¢å¤
```bash
# å¤‡ä»½å½“å‰æ•°æ®åº“
cp outputs/human_review.db backups/human_review_$(date +%Y%m%d).db

# å¦‚æœæ•°æ®åº“æŸåï¼Œé‡æ–°åˆå§‹åŒ–
python -c "
from human_collaboration import HumanCollaborationManager
hcm = HumanCollaborationManager()
print('æ•°æ®åº“é‡æ–°åˆå§‹åŒ–å®Œæˆ')
"
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. ç³»ç»Ÿçº§ä¼˜åŒ–

#### å†…å­˜ä¼˜åŒ–
```python
# åœ¨config.pyä¸­æ·»åŠ å†…å­˜ä¼˜åŒ–é…ç½®
OPTIMIZATION_CONFIG = {
    'batch_size': 100,           # æ‰¹å¤„ç†å¤§å°
    'max_concurrent_requests': 5, # æœ€å¤§å¹¶å‘è¯·æ±‚
    'memory_limit_mb': 2048,     # å†…å­˜é™åˆ¶
    'gc_frequency': 10           # åƒåœ¾å›æ”¶é¢‘ç‡
}
```

#### ç½‘ç»œä¼˜åŒ–
```python
# æ·»åŠ è¯·æ±‚ä¼˜åŒ–
NETWORK_OPTIMIZATION = {
    'connection_pool_size': 10,
    'max_retries': 3,
    'retry_delay': 2,
    'request_timeout': 30,
    'use_session_reuse': True
}
```

### 2. ä»£ç ä¼˜åŒ–

#### æ•°æ®å¤„ç†ä¼˜åŒ–
```python
# ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®å¤„ç†æ–¹æ³•
import pandas as pd

# å¯ç”¨æ•°æ®ç±»å‹ä¼˜åŒ–
def optimize_dataframe(df):
    """ä¼˜åŒ–DataFrameå†…å­˜ä½¿ç”¨"""
    for col in df.select_dtypes(include=['object']):
        if df[col].nunique() / len(df) < 0.5:
            df[col] = df[col].astype('category')
    
    for col in df.select_dtypes(include=['int64']):
        if df[col].min() >= 0:
            if df[col].max() < 255:
                df[col] = df[col].astype('uint8')
            elif df[col].max() < 65535:
                df[col] = df[col].astype('uint16')
    
    return df
```

#### å¹¶è¡Œå¤„ç†
```python
from concurrent.futures import ThreadPoolExecutor
import asyncio

class OptimizedCollector(PipiadsCollector):
    def parallel_collect(self, keywords):
        """å¹¶è¡Œé‡‡é›†å¤šä¸ªå…³é”®è¯"""
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(self.search_products, [kw]) 
                      for kw in keywords]
            
            for future in futures:
                future.result()
```

### 3. æ€§èƒ½ç›‘æ§

åˆ›å»ºæ€§èƒ½ç›‘æ§è„šæœ¬ `performance_monitor.py`ï¼š
```python
import time
import psutil
import threading
from datetime import datetime

class PerformanceMonitor:
    def __init__(self):
        self.metrics = []
        self.running = False
    
    def start_monitoring(self):
        self.running = True
        thread = threading.Thread(target=self._monitor_loop)
        thread.daemon = True
        thread.start()
    
    def _monitor_loop(self):
        while self.running:
            metrics = {
                'timestamp': datetime.now().isoformat(),
                'cpu_percent': psutil.cpu_percent(),
                'memory_percent': psutil.virtual_memory().percent,
                'disk_io': psutil.disk_io_counters()._asdict(),
                'network_io': psutil.net_io_counters()._asdict()
            }
            self.metrics.append(metrics)
            
            # ä¿ç•™æœ€è¿‘1000ä¸ªæ•°æ®ç‚¹
            if len(self.metrics) > 1000:
                self.metrics = self.metrics[-1000:]
            
            time.sleep(60)  # æ¯åˆ†é’Ÿé‡‡é›†ä¸€æ¬¡
```

---

## å®‰å…¨ç®¡ç†

### 1. å‡­æ®ç®¡ç†

#### ä½¿ç”¨ç¯å¢ƒå˜é‡
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export PIPIADS_USERNAME="your_username"
export PIPIADS_PASSWORD="your_password"

# æˆ–ä½¿ç”¨.envæ–‡ä»¶ï¼ˆç¡®ä¿ä¸æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ï¼‰
echo "PIPIADS_USERNAME=your_username" > .env
echo "PIPIADS_PASSWORD=your_password" >> .env
chmod 600 .env
```

#### åŠ å¯†å­˜å‚¨
```python
from cryptography.fernet import Fernet

class CredentialManager:
    def __init__(self):
        self.key = self._load_or_create_key()
        self.cipher = Fernet(self.key)
    
    def _load_or_create_key(self):
        key_file = 'secret.key'
        if os.path.exists(key_file):
            with open(key_file, 'rb') as f:
                return f.read()
        else:
            key = Fernet.generate_key()
            with open(key_file, 'wb') as f:
                f.write(key)
            os.chmod(key_file, 0o600)
            return key
    
    def encrypt_credential(self, credential):
        return self.cipher.encrypt(credential.encode())
    
    def decrypt_credential(self, encrypted_credential):
        return self.cipher.decrypt(encrypted_credential).decode()
```

### 2. ç½‘ç»œå®‰å…¨

#### ä»£ç†é…ç½®
```python
# é…ç½®ä»£ç†æœåŠ¡å™¨
PROXY_CONFIG = {
    'http': 'http://proxy.company.com:8080',
    'https': 'https://proxy.company.com:8080'
}

# åœ¨requestsä¸­ä½¿ç”¨ä»£ç†
import requests
response = requests.get(url, proxies=PROXY_CONFIG)
```

#### SSLè¯ä¹¦éªŒè¯
```python
# å¯ç”¨SSLè¯ä¹¦éªŒè¯
import ssl
import certifi

ssl_context = ssl.create_default_context(cafile=certifi.where())
```

### 3. è®¿é—®æ§åˆ¶

#### æ–‡ä»¶æƒé™è®¾ç½®
```bash
# è®¾ç½®ä¸¥æ ¼çš„æ–‡ä»¶æƒé™
chmod 700 /opt/pipiads_rpa
chmod 600 /opt/pipiads_rpa/.env
chmod 600 /opt/pipiads_rpa/secret.key
chmod 644 /opt/pipiads_rpa/*.py
chmod 755 /opt/pipiads_rpa/outputs
```

#### ç”¨æˆ·æƒé™ç®¡ç†
```bash
# åˆ›å»ºä¸“ç”¨ç”¨æˆ·
sudo useradd -r -s /bin/false rpa_user
sudo chown -R rpa_user:rpa_group /opt/pipiads_rpa
```

---

## å¤‡ä»½æ¢å¤

### 1. æ•°æ®å¤‡ä»½ç­–ç•¥

#### æ¯æ—¥å¤‡ä»½è„šæœ¬
åˆ›å»º `backup.sh`ï¼š
```bash
#!/bin/bash

BACKUP_DIR="/opt/pipiads_rpa/backups"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="pipiads_rpa_backup_${DATE}"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "${BACKUP_DIR}/${BACKUP_NAME}"

# å¤‡ä»½æ•°æ®æ–‡ä»¶
cp -r outputs/ "${BACKUP_DIR}/${BACKUP_NAME}/"
cp -r logs/ "${BACKUP_DIR}/${BACKUP_NAME}/"

# å¤‡ä»½é…ç½®æ–‡ä»¶
cp config.py "${BACKUP_DIR}/${BACKUP_NAME}/"
cp .env "${BACKUP_DIR}/${BACKUP_NAME}/"

# å‹ç¼©å¤‡ä»½
cd "${BACKUP_DIR}"
tar -czf "${BACKUP_NAME}.tar.gz" "${BACKUP_NAME}"
rm -rf "${BACKUP_NAME}"

# ä¿ç•™æœ€è¿‘30å¤©çš„å¤‡ä»½
find "${BACKUP_DIR}" -name "*.tar.gz" -mtime +30 -delete

echo "å¤‡ä»½å®Œæˆ: ${BACKUP_NAME}.tar.gz"
```

#### è‡ªåŠ¨å¤‡ä»½é…ç½®
```bash
# æ·»åŠ åˆ°crontab
crontab -e

# æ¯æ—¥2ç‚¹æ‰§è¡Œå¤‡ä»½
0 2 * * * /opt/pipiads_rpa/backup.sh
```

### 2. äº‘ç«¯å¤‡ä»½

#### AWS S3å¤‡ä»½
```python
import boto3
from datetime import datetime

class CloudBackup:
    def __init__(self):
        self.s3_client = boto3.client('s3')
        self.bucket_name = 'pipiads-rpa-backups'
    
    def upload_backup(self, file_path):
        """ä¸Šä¼ å¤‡ä»½åˆ°S3"""
        key = f"backups/{datetime.now().strftime('%Y/%m/%d')}/{os.path.basename(file_path)}"
        
        try:
            self.s3_client.upload_file(file_path, self.bucket_name, key)
            print(f"å¤‡ä»½å·²ä¸Šä¼ : s3://{self.bucket_name}/{key}")
        except Exception as e:
            print(f"ä¸Šä¼ å¤±è´¥: {e}")
```

### 3. ç¾éš¾æ¢å¤

#### å¿«é€Ÿæ¢å¤è„šæœ¬
åˆ›å»º `restore.sh`ï¼š
```bash
#!/bin/bash

if [ $# -eq 0 ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <backup_file>"
    exit 1
fi

BACKUP_FILE=$1
RESTORE_DIR="/opt/pipiads_rpa"

# åœæ­¢æœåŠ¡
sudo systemctl stop pipiads-rpa

# å¤‡ä»½å½“å‰çŠ¶æ€
cp -r "${RESTORE_DIR}/outputs" "${RESTORE_DIR}/outputs.backup.$(date +%Y%m%d_%H%M%S)"

# è§£å‹æ¢å¤æ–‡ä»¶
cd "${RESTORE_DIR}"
tar -xzf "$BACKUP_FILE"

# ç§»åŠ¨æ–‡ä»¶åˆ°æ­£ç¡®ä½ç½®
BACKUP_NAME=$(basename "$BACKUP_FILE" .tar.gz)
cp -r "${BACKUP_NAME}/outputs/"* outputs/
cp -r "${BACKUP_NAME}/logs/"* logs/

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -rf "$BACKUP_NAME"

# ä¿®å¤æƒé™
chown -R rpa_user:rpa_group "${RESTORE_DIR}"

# é‡å¯æœåŠ¡
sudo systemctl start pipiads-rpa

echo "æ¢å¤å®Œæˆ"
```

---

## å‡çº§ç»´æŠ¤

### 1. ç‰ˆæœ¬ç®¡ç†

#### ç‰ˆæœ¬æ§åˆ¶ç­–ç•¥
```
v1.0.0 - åˆå§‹ç‰ˆæœ¬
v1.1.0 - åŠŸèƒ½å¢å¼º
v1.1.1 - Bugä¿®å¤
```

#### æ›´æ–°æ£€æŸ¥è„šæœ¬
```python
import requests
import json
from packaging import version

def check_for_updates():
    """æ£€æŸ¥æ˜¯å¦æœ‰æ–°ç‰ˆæœ¬"""
    current_version = "1.0.0"
    
    try:
        # ä»GitHubæˆ–å†…éƒ¨æœåŠ¡å™¨æ£€æŸ¥æœ€æ–°ç‰ˆæœ¬
        response = requests.get("https://api.github.com/repos/company/pipiads-rpa/releases/latest")
        latest_release = response.json()
        latest_version = latest_release['tag_name'].lstrip('v')
        
        if version.parse(latest_version) > version.parse(current_version):
            print(f"å‘ç°æ–°ç‰ˆæœ¬: {latest_version}")
            return latest_version
        else:
            print("å½“å‰ç‰ˆæœ¬æ˜¯æœ€æ–°çš„")
            return None
            
    except Exception as e:
        print(f"æ£€æŸ¥æ›´æ–°å¤±è´¥: {e}")
        return None
```

### 2. è‡ªåŠ¨æ›´æ–°

#### æ›´æ–°è„šæœ¬
åˆ›å»º `update.sh`ï¼š
```bash
#!/bin/bash

NEW_VERSION=$1

if [ -z "$NEW_VERSION" ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <new_version>"
    exit 1
fi

# å¤‡ä»½å½“å‰ç‰ˆæœ¬
echo "å¤‡ä»½å½“å‰ç‰ˆæœ¬..."
./backup.sh

# åœæ­¢æœåŠ¡
echo "åœæ­¢æœåŠ¡..."
sudo systemctl stop pipiads-rpa

# ä¸‹è½½æ–°ç‰ˆæœ¬
echo "ä¸‹è½½æ–°ç‰ˆæœ¬ $NEW_VERSION..."
wget "https://github.com/company/pipiads-rpa/archive/v${NEW_VERSION}.tar.gz" -O "v${NEW_VERSION}.tar.gz"

# è§£å‹æ–°ç‰ˆæœ¬
tar -xzf "v${NEW_VERSION}.tar.gz"

# æ›´æ–°æ–‡ä»¶
echo "æ›´æ–°æ–‡ä»¶..."
cp "pipiads-rpa-${NEW_VERSION}"/*.py ./
cp "pipiads-rpa-${NEW_VERSION}"/requirements.txt ./

# æ›´æ–°ä¾èµ–
echo "æ›´æ–°ä¾èµ–..."
pip install -r requirements.txt --upgrade

# è¿è¡Œæ•°æ®åº“è¿ç§»ï¼ˆå¦‚æœ‰ï¼‰
echo "è¿è¡Œæ•°æ®åº“è¿ç§»..."
python migrate.py

# é‡å¯æœåŠ¡
echo "é‡å¯æœåŠ¡..."
sudo systemctl start pipiads-rpa

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -rf "pipiads-rpa-${NEW_VERSION}" "v${NEW_VERSION}.tar.gz"

echo "æ›´æ–°å®Œæˆåˆ°ç‰ˆæœ¬ $NEW_VERSION"
```

### 3. ç»´æŠ¤ä»»åŠ¡

#### å®šæœŸç»´æŠ¤è„šæœ¬
åˆ›å»º `maintenance.py`ï¼š
```python
import os
import glob
import sqlite3
from datetime import datetime, timedelta

def daily_maintenance():
    """æ¯æ—¥ç»´æŠ¤ä»»åŠ¡"""
    print("å¼€å§‹æ¯æ—¥ç»´æŠ¤...")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    temp_files = glob.glob('downloads/*.tmp')
    for file in temp_files:
        os.remove(file)
    
    # å‹ç¼©æ—§æ—¥å¿—
    old_logs = glob.glob('logs/*.log.*')
    for log in old_logs:
        if os.path.getmtime(log) < (datetime.now() - timedelta(days=7)).timestamp():
            os.system(f'gzip {log}')
    
    # ä¼˜åŒ–æ•°æ®åº“
    db_path = 'outputs/human_review.db'
    if os.path.exists(db_path):
        conn = sqlite3.connect(db_path)
        conn.execute('VACUUM')
        conn.close()
    
    print("æ¯æ—¥ç»´æŠ¤å®Œæˆ")

def weekly_maintenance():
    """æ¯å‘¨ç»´æŠ¤ä»»åŠ¡"""
    print("å¼€å§‹æ¯å‘¨ç»´æŠ¤...")
    
    # æ¸…ç†è¿‡æœŸçš„Excelæ–‡ä»¶
    excel_files = glob.glob('outputs/*.xlsx')
    for file in excel_files:
        if os.path.getmtime(file) < (datetime.now() - timedelta(days=30)).timestamp():
            os.remove(file)
    
    # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    generate_performance_report()
    
    print("æ¯å‘¨ç»´æŠ¤å®Œæˆ")

def generate_performance_report():
    """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
    # åˆ†ææ—¥å¿—æ–‡ä»¶ï¼Œç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    pass
```

#### å¥åº·æ£€æŸ¥
```python
def system_health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    issues = []
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    disk_usage = psutil.disk_usage('/')
    if disk_usage.percent > 85:
        issues.append(f"ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {disk_usage.percent}%")
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨
    memory = psutil.virtual_memory()
    if memory.percent > 90:
        issues.append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory.percent}%")
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    try:
        result = os.system('systemctl is-active --quiet pipiads-rpa')
        if result != 0:
            issues.append("RPAæœåŠ¡æœªè¿è¡Œ")
    except:
        issues.append("æ— æ³•æ£€æŸ¥æœåŠ¡çŠ¶æ€")
    
    # æ£€æŸ¥æœ€è¿‘çš„é”™è¯¯æ—¥å¿—
    recent_errors = check_recent_errors()
    if recent_errors > 10:
        issues.append(f"æœ€è¿‘24å°æ—¶å†…æœ‰ {recent_errors} ä¸ªé”™è¯¯")
    
    return issues

def check_recent_errors():
    """æ£€æŸ¥æœ€è¿‘çš„é”™è¯¯æ•°é‡"""
    log_file = f"logs/activity_{datetime.now().strftime('%Y%m%d')}.log"
    if not os.path.exists(log_file):
        return 0
    
    error_count = 0
    cutoff_time = datetime.now() - timedelta(hours=24)
    
    with open(log_file, 'r') as f:
        for line in f:
            if 'ERROR' in line:
                # ç®€å•çš„æ—¶é—´è§£æï¼ˆå®é™…åº”è¯¥æ›´ä¸¥æ ¼ï¼‰
                error_count += 1
    
    return error_count
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### è”ç³»ä¿¡æ¯
- **æŠ€æœ¯æ”¯æŒé‚®ç®±ï¼š** rpa-support@company.com
- **ç´§æ€¥çƒ­çº¿ï¼š** +86-xxx-xxxx-xxxx
- **æ–‡æ¡£æ›´æ–°ï¼š** æ¯å­£åº¦æ›´æ–°

### æ•…éšœæŠ¥å‘Šæ¨¡æ¿
```
æ•…éšœæŠ¥å‘Š
=========
æ—¶é—´: ___________
ç‰ˆæœ¬: ___________
ç¯å¢ƒ: ___________
é”™è¯¯æè¿°: ___________
é”™è¯¯æ—¥å¿—: ___________
é‡ç°æ­¥éª¤: ___________
å½±å“èŒƒå›´: ___________
```

### æ›´æ–°æ—¥å¿—
- **v1.0.0** (2024-01-01): åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- **v1.1.0** (2024-04-01): å¢åŠ äººæœºåä½œåŠŸèƒ½
- **v1.2.0** (2024-07-01): æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯ä¿®å¤

---

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** v1.0  
**æœ€åæ›´æ–°ï¼š** 2024å¹´1æœˆ1æ—¥  
**ä¸‹æ¬¡æ›´æ–°ï¼š** 2024å¹´4æœˆ1æ—¥

*æœ¬æ–‡æ¡£ä¸ºå†…éƒ¨æŠ€æœ¯æ–‡æ¡£ï¼Œè¯·å¦¥å–„ä¿ç®¡*