#!/usr/bin/env python3

"""
30å¤©äº§å“åˆ†ææ•°æ®æŠ“å–è„šæœ¬
è‡ªåŠ¨æŠ“å–ã€å¤„ç†å’Œä¿å­˜åˆ°product_analytics2è¡¨
åˆ©ç”¨ç°æœ‰sync_saihu_erpç³»ç»Ÿ
"""

import sys
import os
import asyncio
import json
from datetime import datetime, timedelta, date
from decimal import Decimal
import logging
from typing import List, Dict, Any

# æ·»åŠ åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'sync_saihu_erp', 'data_update', 'src'))

from models.product_analytics import ProductAnalytics
from services.data_sync_service import DataSyncService
from database.postgresql_connection import PostgreSQLManager
from scrapers.product_analytics_scraper import ProductAnalyticsScraper

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ProductAnalytics30DaysGrabber:
    def __init__(self):
        self.db = PostgreSQLManager()
        self.sync_service = DataSyncService()
        self.scraper = ProductAnalyticsScraper()
        
        self.target_date = date.today() - timedelta(days=1)
        self.start_date = self.target_date - timedelta(days=30)
        self.end_date = self.target_date
        
        logger.info(f"ğŸ“… å‡†å¤‡æŠ“å–30å¤©æ•°æ®èŒƒå›´: {self.start_date} åˆ° {self.end_date}")
    
    async def grab_product_analytics_30days(self, warehouse_location="æ¬§ç›Ÿ"):
        """æŠ“å–30å¤©äº§å“åˆ†ææ•°æ®"""
        try:
            logger.info("ğŸš€ å¼€å§‹30å¤©æ•°æ®æŠ“å–æµç¨‹...")
            
            # 1. è·å–éœ€è¦æŠ“å–çš„ASINåˆ—è¡¨
            asin_list = await self.get_asin_list()
            logger.info(f"ğŸ“‹ è·å–åˆ° {len(asin_list)} ä¸ªéœ€è¦æŠ“å–çš„ASIN")
            
            all_records = []
            
            # 2. æŒ‰æ—¥æœŸæ‰¹é‡æŠ“å–
            current_date = self.start_date
            while current_date <= self.end_date:
                logger.info(f"ğŸ“ˆ æŠ“å–æ—¥æœŸ: {current_date}")
                
                try:
                    # ä½¿ç”¨ç°æœ‰æŠ“å–å™¨è·å–æ•°æ®
                    api_response = await self.extract_product_analytics(
                        date_list=[current_date],
                        asin_list=asin_list,
                        warehouse_location=warehouse_location
                    )
                    
                    # 3. æ•°æ®è½¬æ¢å’ŒéªŒè¯
                    records = await self.process_api_response(
                        api_response, 
                        current_date
                    )
                    
                    logger.info(f"ğŸ“Š ä» {current_date} è·å–äº† {len(records)} æ¡è®°å½•")
                    all_records.extend(records)
                    
                except Exception as e:
                    logger.error(f"âŒ æŠ“å– {current_date} æ—¶å‡ºé”™: {e}")
                
                current_date += timedelta(days=1)
            
            # 4. ä¿å­˜åˆ°product_analytics2
            saved_count = await self.save_to_product_analytics2(all_records)
            
            # 5. æ•°æ®éªŒè¯å’ŒæŠ¥å‘Š
            await self.validate_data(saved_count)
            
            return {
                'total_records': len(all_records),
                'saved_records': saved_count,
                'date_range': f"{self.start_date} åˆ° {self.end_date}",
                'status': 'success'
            }
            
        except Exception as e:
            logger.error(f"âŒ 30å¤©æ•°æ®æŠ“å–å¤±è´¥: {e}")
            return {
                'total_records': 0,
                'saved_records': 0,
                'error': str(e),
                'status': 'failed'
            }
    
    async def get_asin_list(self) -> List[str]:
        """è·å–éœ€è¦æŠ“å–çš„ASINåˆ—è¡¨"""
        try:
            with self.db.get_db_connection() as conn:
                cursor = conn.cursor()
                # ä»ç°æœ‰çš„äº§å“æ•°æ®è·å–æ´»è·ƒASIN
                cursor.execute("""
                    SELECT DISTINCT asin 
                    FROM inventory_records 
                    WHERE date >= %s AND date <= %s 
                    AND total_inventory IS NOT NULL
                    AND total_inventory > 0
                """, (self.start_date, self.end_date))
                
                result = cursor.fetchall()
                asin_list = [row[0] for row in result if row[0]]
                
                # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•ASIN
                if not asin_list:
                    logger.info("ğŸ“‹ ä½¿ç”¨é»˜è®¤æµ‹è¯•ASINåˆ—è¡¨")
                    asin_list = [
                        'B08XYZ123',  # ç¤ºä¾‹ASIN 1
                        'B09DEF456',  # ç¤ºä¾‹ASIN 2  
                        'B10GHI789'   # ç¤ºä¾‹ASIN 3
                    ]
                
                return asin_list
                
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•è·å–ASINåˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            return ['B08XYZ123', 'B09DEF456', 'B10GHI789']
    
    async def extract_product_analytics(self, date_list: List[date], asin_list: List[str], warehouse_location: str) -> Dict[str, Any]:
        """æå–äº§å“åˆ†ææ•°æ®ï¼Œå¤ç”¨ç°æœ‰é€»è¾‘"""
        try:
            # ä½¿ç”¨ç°æœ‰çš„ProductAnalyticsScraper
            sync_data = {
                'date_list': [d.strftime('%Y-%m-%d') for d in date_list],
                'asin_list': asin_list,
                'warehouse_location': warehouse_location,
                'batch_size': len(asin_list) * len(date_list)
            }
            
            logger.info(f"ğŸ” å‡†å¤‡æŠ“å– {len(asin_list)} ä¸ªASIN, {len(date_list)} å¤©æ•°æ®")
            
            # è°ƒç”¨ç°æœ‰æŠ“å–é€»è¾‘
            api_response = self.scraper.scrape_data(
                start_date=min(date_list).strftime('%Y-%m-%d'),
                end_date=max(date_list).strftime('%Y-%m-%d'),
                asin_list=asin_list,
                marketplace_id='EU'  # å‡è®¾æ¬§ç›Ÿåœ°åŒº
            )
            
            return api_response
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®æå–å¤±è´¥: {e}")
            raise
    
    async def process_api_response(self, api_response: Dict[str, Any], current_date: date) -> List[ProductAnalytics]:
        """å¤„ç†APIå“åº”æ•°æ®"""
        records = []
        
        if api_response and 'data' in api_response:
            api_data = api_response.get('data', [])
            
            for item in api_data:
                try:
                    # ä½¿ç”¨ç°æœ‰æ¨¡å‹çš„from_api_responseæ–¹æ³•
                    analysis = ProductAnalytics.from_api_response(item, current_date)
                    
                    # è®¾ç½®é¢å¤–ä¿¡æ¯
                    analysis.data_source = 'manual_30day_sync'
                    analysis.created_at = datetime.now()
                    analysis.updated_at = datetime.now()
                    
                    if analysis.is_valid():
                        records.append(analysis)
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ å¤„ç†å•æ¡è®°å½•å¤±è´¥: {e}")
                    continue
        
        return records
    
    async def save_to_product_analytics2(self, records: List[ProductAnalytics]) -> int:
        """ä¿å­˜æ•°æ®åˆ°product_analytics2è¡¨"""
        try:
            saved_count = 0
            batch_size = 1000
            
            for i in range(0, len(records), batch_size):
                batch = records[i:i + batch_size]
                batch_saved = await self.batch_save_records(batch)
                saved_count += batch_saved
                logger.info(f"ğŸ“Š å·²ä¿å­˜ {saved_count}/{len(records)} æ¡è®°å½•")
                
            return saved_count
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®ä¿å­˜å¤±è´¥: {e}")
            raise
    
    async def batch_save_records(self, records: List[ProductAnalytics]) -> int:
        """æ‰¹é‡ä¿å­˜è®°å½•"""
        try:
            with self.db.get_db_transaction() as conn:
                cursor = conn.cursor()
                
                insert_query = """
                    INSERT INTO product_analytics2 (
                        product_id, asin, sku, spu, msku, data_date,
                        sales_amount, sales_quantity, impressions, clicks,
                        conversion_rate, acos, marketplace_id, dev_name, operator_name,
                        ad_cost, ad_sales, ad_orders, fba_inventory, total_inventory,
                        currency, created_at, updated_at, data_source, sync_status
                    ) VALUES %s
                    ON CONFLICT (product_id, asin, data_date, marketplace_id) DO UPDATE SET
                        sales_amount = EXCLUDED.sales_amount,
                        sales_quantity = EXCLUDED.sales_quantity,
                        impressions = EXCLUDED.impressions,
                        clicks = EXCLUDED.clicks,
                        conversion_rate = EXCLUDED.conversion_rate,
                        acos = EXCLUDED.acos,
                        ad_cost = EXCLUDED.ad_cost,
        
                        ad_sales = EXCLUDED.ad_sales,
                        ad_orders = EXCLUDED.ad_orders,
                        fba_inventory = EXCLUDED.fba_inventory,
                        total_inventory = EXCLUDED.total_inventory,
                        updated_at = EXCLUDED.updated_at,
                        sync_status = 'updated'
                """
                
                values = []
                for record in records:
                    values.append((
                        record.product_id,
                        record.asin,
                        record.sku,
                        record.spu,
                        record.msku,
                        record.data_date,
                        record.sales_amount,
                        record.sales_quantity,
                        record.impressions,
                        record.clicks,
                        record.conversion_rate,
                        record.acos,
                        record.marketplace_id,
                        record.dev_name,
                        record.operator_name,
                        record.ad_cost if hasattr(record, 'ad_cost') else 0,
                        record.ad_sales if hasattr(record, 'ad_sales') else 0,
                        record.ad_orders if hasattr(record, 'ad_orders') else 0, 
                        record.fba_inventory if hasattr(record, 'fba_inventory') else 0,
                        record.total_inventory if hasattr(record, 'total_inventory') else 0,
                        'USD',
                        record.created_at,
                        record.updated_at
                    ))
                
                from psycopg2.extras import execute_values
                execute_values(cursor, insert_query, values)
                
                return len(records)
                
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡ä¿å­˜å¤±è´¥: {e}")
            conn.rollback()
            return 0
    
    async def validate_data(self, saved_count: int):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        try:
            with self.db.get_db_connection() as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT 
                        COUNT(*) as total_records,
                        COUNT(DISTINCT asin) as unique_asins,
                        MIN(data_date) as earliest_date,
                        MAX(data_date) as latest_date,
                        SUM(sales_amount) as total_sales,
                        SUM(impressions) as total_impressions
                    FROM product_analytics2 
                    WHERE data_date BETWEEN %s AND %s
                """, (self.start_date, self.end_date))
                
                validation = cursor.fetchone()
                
                logger.info("âœ… æ•°æ®éªŒè¯å®Œæˆ:")
                logger.info(f"ğŸ“Š æ€»è®°å½•æ•°: {validation[0]}")
                logger.info(f"ğŸ·ï¸  å”¯ä¸€ASINæ•°: {validation[1]}")
                logger.info(f"ğŸ“… æ•°æ®èŒƒå›´: {validation[2]} åˆ° {validation[3]}")
                logger.info(f"ğŸ’° æ€»é”€å”®é¢: {validation[4]}")
                logger.info(f"ğŸ‘ï¸  æ€»æ›å…‰é‡: {validation[5]}")
                
        except Exception as e:
            logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    import asyncio
    
    async def run():
        grabber = ProductAnalytics30DaysGrabber()
        result = await grabber.grab_product_analytics_30days()
        
        logger.info("=" * 50)
        logger.info("ğŸ¯ 30å¤©æ•°æ®æŠ“å–å®Œæˆ") 
        logger.info(f"æ€»è®¡: {result}")
        logger.info("=" * 50)
        
        return result
    
    return asyncio.run(run())

if __name__ == "__main__":
    result = main()
    print(json.dumps(result, indent=2, default=str))