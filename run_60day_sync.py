#!/usr/bin/env python3
"""
æ‰§è¡Œ60å¤©äº§å“åˆ†ææ•°æ®åŒæ­¥è„šæœ¬
ä»æœ€ååŒæ­¥çš„æ—¶é—´å¼€å§‹ï¼Œå†åŒæ­¥30å¤©ï¼Œå®ç°æ€»å…±60å¤©çš„æ•°æ®åŒæ­¥
"""

import sys
import os
from datetime import datetime, date, timedelta
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(__file__)
sync_path = os.path.join(project_root, "sync_saihu_erp", "data_update")
sys.path.insert(0, sync_path)

from src.scheduler.sync_jobs import SyncJobs
from src.config.settings import settings
from src.utils.logging_utils import setup_logging
from src.database import db_manager

def get_last_sync_date():
    """è·å–æ•°æ®åº“ä¸­æœ€ååŒæ­¥çš„æ—¥æœŸ"""
    try:
        # æŸ¥è¯¢product_analyticsè¡¨ä¸­æœ€æ–°çš„æ•°æ®æ—¥æœŸ
        result = db_manager.execute_single(
            "SELECT MAX(data_date) as last_date FROM product_analytics"
        )
        
        if result and result.get('last_date'):
            last_date = result['last_date']
            print(f"ğŸ“… æ•°æ®åº“ä¸­æœ€ååŒæ­¥æ—¥æœŸ: {last_date}")
            return last_date
        else:
            print("âš ï¸ æ•°æ®åº“ä¸­æ— å†å²æ•°æ®ï¼Œå°†ä»30å¤©å‰å¼€å§‹åŒæ­¥")
            return None
            
    except Exception as e:
        print(f"âŒ è·å–æœ€ååŒæ­¥æ—¥æœŸå¤±è´¥: {e}")
        return None

def calculate_sync_range(last_sync_date=None, additional_days=30):
    """
    è®¡ç®—åŒæ­¥æ—¥æœŸèŒƒå›´
    
    Args:
        last_sync_date: æœ€ååŒæ­¥çš„æ—¥æœŸï¼Œå¦‚æœä¸ºNoneåˆ™ä»30+additional_dayså¤©å‰å¼€å§‹
        additional_days: é¢å¤–éœ€è¦åŒæ­¥çš„å¤©æ•°ï¼Œé»˜è®¤30å¤©
        
    Returns:
        tuple: (start_date, end_date) éœ€è¦åŒæ­¥çš„æ—¥æœŸèŒƒå›´
    """
    today = date.today()
    
    if last_sync_date:
        # ä»æœ€ååŒæ­¥æ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹
        if isinstance(last_sync_date, str):
            last_sync_date = datetime.strptime(last_sync_date, '%Y-%m-%d').date()
        
        start_date = last_sync_date + timedelta(days=1)
        end_date = start_date + timedelta(days=additional_days - 1)
        
        # ç¡®ä¿ä¸è¶…è¿‡æ˜¨å¤©
        yesterday = today - timedelta(days=1)
        if end_date > yesterday:
            end_date = yesterday
        
        print(f"ğŸ“Š ç»§ç»­åŒæ­¥æ¨¡å¼:")
        print(f"   æœ€ååŒæ­¥æ—¥æœŸ: {last_sync_date}")
        print(f"   æ–°åŒæ­¥èŒƒå›´: {start_date} åˆ° {end_date}")
        print(f"   æ–°å¢å¤©æ•°: {(end_date - start_date).days + 1}")
        
    else:
        # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼ŒåŒæ­¥æœ€è¿‘60å¤©
        total_days = 60
        end_date = today - timedelta(days=1)
        start_date = end_date - timedelta(days=total_days - 1)
        
        print(f"ğŸ“Š é¦–æ¬¡åŒæ­¥æ¨¡å¼:")
        print(f"   åŒæ­¥èŒƒå›´: {start_date} åˆ° {end_date}")
        print(f"   æ€»å¤©æ•°: {total_days}")
    
    return start_date, end_date

def sync_date_range(sync_jobs, start_date, end_date):
    """
    æŒ‰æ—¥æœŸèŒƒå›´åŒæ­¥äº§å“åˆ†ææ•°æ®
    
    Args:
        sync_jobs: SyncJobså®ä¾‹
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        
    Returns:
        dict: åŒæ­¥ç»“æœ
    """
    print(f"\nğŸ”„ å¼€å§‹æŒ‰æ—¥æœŸèŒƒå›´åŒæ­¥: {start_date} åˆ° {end_date}")
    
    results = []
    success_count = 0
    current_date = start_date
    
    while current_date <= end_date:
        date_str = current_date.strftime('%Y-%m-%d')
        print(f"   æ­£åœ¨åŒæ­¥ {date_str}...")
        
        try:
            result = sync_jobs.sync_product_analytics_by_date(date_str)
            results.append(result)
            
            if result.get('status') == 'success':
                success_count += 1
                processed_count = result.get('processed_count', 0)
                print(f"   âœ… {date_str}: {processed_count} æ¡è®°å½•")
            else:
                error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                print(f"   âŒ {date_str}: {error_msg}")
                
        except Exception as e:
            print(f"   âŒ {date_str}: åŒæ­¥å¼‚å¸¸ - {e}")
            results.append({
                'status': 'error',
                'data_date': date_str,
                'error': str(e)
            })
        
        current_date += timedelta(days=1)
    
    total_days = (end_date - start_date).days + 1
    
    return {
        'status': 'completed' if success_count > 0 else 'failed',
        'total_days': total_days,
        'success_count': success_count,
        'failure_count': total_days - success_count,
        'results': results
    }

def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œ60å¤©æ•°æ®åŒæ­¥"""
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ60å¤©äº§å“åˆ†ææ•°æ®åŒæ­¥...")
    print(f"ğŸ“… æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    # åˆå§‹åŒ–åŒæ­¥ä½œä¸š
    sync_jobs = SyncJobs()
    start_time = datetime.now()
    
    # æ‰§è¡Œç»“æœæ±‡æ€»
    results = {
        'start_time': start_time.isoformat(),
        'sync_type': '60day_extended',
        'tasks': []
    }
    
    # è·å–APIé…ç½®å’Œå‡­æ®æ£€æŸ¥
    api_config = settings.get('api', {})
    print(f"ğŸ”§ APIé…ç½®æ£€æŸ¥:")
    print(f"   Base URL: {api_config.get('base_url', 'N/A')}")

    try:
        from src.config.secure_config import config
        from src.auth.oauth_client import oauth_client
        creds = config.get_api_credentials()
        print(f"   Client ID: {creds.client_id}")
        
        # è¯•å›¾è·å–ä¸€æ¬¡è®¿é—®ä»¤ç‰Œ
        token = oauth_client.get_access_token()
        if not token:
            raise RuntimeError("æ— æ³•è·å–è®¿é—®ä»¤ç‰Œï¼Œè¯·æ£€æŸ¥ SELLFOX_CLIENT_ID/SELLFOX_CLIENT_SECRET æ˜¯å¦æ­£ç¡®")
        print("   è®¿é—®ä»¤ç‰Œ: âœ… å·²è·å–")
    except Exception as precheck_err:
        print(f"âŒ å‡­æ®é¢„æ£€å¤±è´¥: {precheck_err}")
        return False
    
    try:
        # WebçŠ¶æ€é›†æˆ
        from src.utils.web_integration import report_status, report_progress, report_error, report_completed
        report_status('started', '60å¤©æ‰©å±•æ•°æ®åŒæ­¥å·²å¯åŠ¨')
        
        # æ­¥éª¤1: è·å–æœ€ååŒæ­¥æ—¥æœŸ
        print("\nğŸ“Š æ­¥éª¤1: åˆ†æç°æœ‰æ•°æ®")
        last_sync_date = get_last_sync_date()
        
        # æ­¥éª¤2: è®¡ç®—éœ€è¦åŒæ­¥çš„æ—¥æœŸèŒƒå›´
        print("\nğŸ“Š æ­¥éª¤2: è®¡ç®—åŒæ­¥èŒƒå›´")
        start_date, end_date = calculate_sync_range(last_sync_date, additional_days=30)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åŒæ­¥
        if start_date > end_date:
            print("âœ… æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€é¢å¤–åŒæ­¥")
            results['message'] = 'æ•°æ®å·²æ˜¯æœ€æ–°çŠ¶æ€'
            results['status'] = 'up_to_date'
            return results
        
        # æ­¥éª¤3: æ‰§è¡Œæ—¥æœŸèŒƒå›´åŒæ­¥
        print(f"\nğŸ“Š æ­¥éª¤3: æ‰§è¡Œæ‰©å±•åŒæ­¥")
        report_progress('æ­£åœ¨æ‰§è¡Œæ‰©å±•åŒæ­¥', 30)
        
        sync_result = sync_date_range(sync_jobs, start_date, end_date)
        results['tasks'].append({
            'task': 'extended_product_analytics',
            'date_range': f"{start_date} åˆ° {end_date}",
            'result': sync_result
        })
        
        # æ˜¾ç¤ºåŒæ­¥ç»“æœ
        if sync_result.get('status') == 'completed':
            total_days = sync_result.get('total_days', 0)
            success_count = sync_result.get('success_count', 0)
            failure_count = sync_result.get('failure_count', 0)
            
            print(f"\nâœ… æ‰©å±•åŒæ­¥å®Œæˆ:")
            print(f"   ç›®æ ‡å¤©æ•°: {total_days}")
            print(f"   æˆåŠŸå¤©æ•°: {success_count}")
            print(f"   å¤±è´¥å¤©æ•°: {failure_count}")
            print(f"   æˆåŠŸç‡: {success_count/total_days*100:.1f}%")
            
            # æ˜¾ç¤ºè¿‘æœŸæˆåŠŸçš„åŒæ­¥è¯¦æƒ…
            recent_success = [r for r in sync_result.get('results', []) if r.get('status') == 'success'][-5:]
            if recent_success:
                print(f"   è¿‘æœŸæˆåŠŸåŒæ­¥:")
                for result in recent_success:
                    date_str = result.get('data_date', 'N/A')
                    count = result.get('processed_count', 0)
                    print(f"     âœ… {date_str}: {count} æ¡è®°å½•")
        else:
            print(f"âŒ æ‰©å±•åŒæ­¥å¤±è´¥: {sync_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            report_error(f"æ‰©å±•åŒæ­¥å¤±è´¥")
        
        # æ­¥éª¤4: åŒæ­¥å…¶ä»–æ•°æ®ç±»å‹
        print(f"\nğŸ“Š æ­¥éª¤4: åŒæ­¥å…¶ä»–æ•°æ®ç±»å‹")
        
        # åŒæ­¥FBAåº“å­˜
        print("ğŸ“¦ åŒæ­¥FBAåº“å­˜æ•°æ®...")
        report_progress('æ­£åœ¨åŒæ­¥FBAåº“å­˜', 70)
        fba_result = sync_jobs.sync_fba_inventory()
        results['tasks'].append({
            'task': 'fba_inventory',
            'result': fba_result
        })
        
        if fba_result.get('status') == 'success':
            print(f"âœ… FBAåº“å­˜åŒæ­¥æˆåŠŸ: {fba_result.get('data_count', 0)} æ¡")
        else:
            print(f"âŒ FBAåº“å­˜åŒæ­¥å¤±è´¥: {fba_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # åŒæ­¥åº“å­˜æ˜ç»†
        print("ğŸ” åŒæ­¥åº“å­˜æ˜ç»†æ•°æ®...")
        report_progress('æ­£åœ¨åŒæ­¥åº“å­˜æ˜ç»†', 85)
        inventory_result = sync_jobs.sync_inventory_details()
        results['tasks'].append({
            'task': 'inventory_details',
            'result': inventory_result
        })
        
        if inventory_result.get('status') == 'success':
            print(f"âœ… åº“å­˜æ˜ç»†åŒæ­¥æˆåŠŸ: {inventory_result.get('data_count', 0)} æ¡")
        else:
            print(f"âŒ åº“å­˜æ˜ç»†åŒæ­¥å¤±è´¥: {inventory_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # æ­¥éª¤5: éªŒè¯æœ€ç»ˆæ•°æ®çŠ¶æ€
        print(f"\nğŸ“Š æ­¥éª¤5: éªŒè¯æ•°æ®å®Œæ•´æ€§")
        report_progress('éªŒè¯æ•°æ®å®Œæ•´æ€§', 95)
        
        # æ£€æŸ¥æ€»è®°å½•æ•°
        total_count_result = db_manager.execute_single("SELECT COUNT(*) AS count FROM product_analytics")
        total_count = total_count_result.get('count', 0) if total_count_result else 0
        print(f"   äº§å“åˆ†ææ•°æ®æ€»è®¡: {total_count} æ¡")
        
        # æ£€æŸ¥æ—¥æœŸåˆ†å¸ƒ
        date_range_result = db_manager.execute_single(
            "SELECT MIN(data_date) as min_date, MAX(data_date) as max_date FROM product_analytics"
        )
        if date_range_result:
            min_date = date_range_result.get('min_date')
            max_date = date_range_result.get('max_date')
            if min_date and max_date:
                if isinstance(min_date, str):
                    min_date = datetime.strptime(min_date, '%Y-%m-%d').date()
                if isinstance(max_date, str):
                    max_date = datetime.strptime(max_date, '%Y-%m-%d').date()
                
                total_days_in_db = (max_date - min_date).days + 1
                print(f"   æ•°æ®æ—¥æœŸèŒƒå›´: {min_date} åˆ° {max_date}")
                print(f"   è¦†ç›–å¤©æ•°: {total_days_in_db} å¤©")
        
        # æ£€æŸ¥æœ€è¿‘7å¤©æ•°æ®
        recent_data = db_manager.execute_query(
            """
            SELECT data_date, COUNT(*) as count 
            FROM product_analytics 
            WHERE data_date >= CURRENT_DATE - INTERVAL '7 days'
            GROUP BY data_date 
            ORDER BY data_date DESC 
            LIMIT 7
            """
        )
        
        if recent_data:
            print(f"   æœ€è¿‘7å¤©æ•°æ®åˆ†å¸ƒ:")
            for row in recent_data:
                date_str = row.get('data_date')
                count = row.get('count', 0)
                print(f"     {date_str}: {count} æ¡è®°å½•")
        
        # è®¡ç®—æ€»å¤„ç†è®°å½•æ•°å¹¶å®ŒæˆæŠ¥å‘Š
        end_time = datetime.now()
        duration = end_time - start_time
        duration_seconds = duration.total_seconds()
        
        total_processed = 0
        for task in results['tasks']:
            task_result = task['result']
            if task_result.get('status') in ['success', 'completed']:
                if 'success_count' in task_result:  # å†å²åŒæ­¥ä»»åŠ¡
                    # è®¡ç®—æˆåŠŸåŒæ­¥çš„å¤©æ•°å¯¹åº”çš„è®°å½•æ•°
                    successful_results = [r for r in task_result.get('results', []) if r.get('status') == 'success']
                    for day_result in successful_results:
                        total_processed += day_result.get('processed_count', 0)
                else:  # å•æ¬¡åŒæ­¥ä»»åŠ¡
                    total_processed += task_result.get('processed_count', task_result.get('data_count', 0))
        
        results['total_processed'] = total_processed
        results['final_total_count'] = total_count
        
        report_completed(total_processed, duration_seconds)
        
        print(f"\nğŸ‰ 60å¤©æ‰©å±•åŒæ­¥å®Œæˆ!")
        print(f"   æ–°å¢å¤„ç†è®°å½•: {total_processed}")
        print(f"   æ•°æ®åº“æ€»è®°å½•: {total_count}")
        print(f"   æ‰§è¡Œæ—¶é•¿: {duration}")
        
    except Exception as e:
        print(f"ğŸš¨ æ•°æ®åŒæ­¥æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        print("é”™è¯¯è¯¦æƒ…:")
        print(traceback.format_exc())
        results['error'] = str(e)
        report_error(str(e))
        return False
    
    finally:
        # ä¿å­˜æ‰§è¡Œç»“æœ
        results['end_time'] = datetime.now().isoformat()
        results['duration'] = str(datetime.now() - start_time)
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        result_filename = 'sync_60day_result.json'
        with open(result_filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ“ æ‰§è¡Œç»“æœå·²ä¿å­˜åˆ°: {result_filename}")
    
    return True

if __name__ == "__main__":
    print("=" * 70)
    print("èµ›ç‹ERPæ•°æ®åŒæ­¥ç³»ç»Ÿ - 60å¤©æ‰©å±•åŒæ­¥")
    print("=" * 70)
    
    success = main()
    if not success:
        sys.exit(1)