#!/usr/bin/env python3
"""
å®Œæ•´æ•°æ®åŒæ­¥æ‰§è¡Œè„šæœ¬
ä½¿ç”¨éªŒè¯è¿‡çš„APIå‡­æ®æ‰§è¡Œæ‰€æœ‰æ•°æ®ç±»å‹çš„åŒæ­¥
"""

import sys
import os
from datetime import datetime, date, timedelta
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.scheduler.sync_jobs import SyncJobs
from src.config.settings import settings
from src.utils.logging_utils import setup_logging

def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„æ•°æ®åŒæ­¥"""
    print("ğŸš€ å¼€å§‹æ‰§è¡Œèµ›ç‹ERPæ•°æ®åŒæ­¥...")
    print(f"ğŸ“… æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    # åˆå§‹åŒ–åŒæ­¥ä½œä¸š
    sync_jobs = SyncJobs()
    
    # æ‰§è¡Œç»“æœæ±‡æ€»
    results = {
        'start_time': datetime.now().isoformat(),
        'tasks': []
    }
    
    try:
        # 1. åŒæ­¥æ˜¨å¤©çš„äº§å“åˆ†ææ•°æ®
        print("\nğŸ“Š 1. åŒæ­¥äº§å“åˆ†ææ•°æ®ï¼ˆæ˜¨å¤©ï¼‰...")
        yesterday = (date.today() - timedelta(days=1)).strftime('%Y-%m-%d')
        analytics_result = sync_jobs.sync_product_analytics_by_date(yesterday)
        results['tasks'].append({
            'task': 'product_analytics_yesterday',
            'date': yesterday,
            'result': analytics_result
        })
        
        if analytics_result.get('status') == 'success':
            print(f"âœ… äº§å“åˆ†ææ•°æ®åŒæ­¥æˆåŠŸ: {analytics_result.get('raw_count', 0)} æ¡åŸå§‹æ•°æ®")
            print(f"   å¤„ç†æˆåŠŸ: {analytics_result.get('processed_count', 0)} æ¡")
            print(f"   åº“å­˜åˆå¹¶: {analytics_result.get('merged_count', 0)} æ¡")
        else:
            print(f"âŒ äº§å“åˆ†ææ•°æ®åŒæ­¥å¤±è´¥: {analytics_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # 2. åŒæ­¥FBAåº“å­˜æ•°æ®
        print("\nğŸ“¦ 2. åŒæ­¥FBAåº“å­˜æ•°æ®...")
        fba_result = sync_jobs.sync_fba_inventory()
        results['tasks'].append({
            'task': 'fba_inventory',
            'result': fba_result
        })
        
        if fba_result.get('status') == 'success':
            print(f"âœ… FBAåº“å­˜æ•°æ®åŒæ­¥æˆåŠŸ: {fba_result.get('data_count', 0)} æ¡æ•°æ®")
        else:
            print(f"âŒ FBAåº“å­˜æ•°æ®åŒæ­¥å¤±è´¥: {fba_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # 3. åŒæ­¥åº“å­˜æ˜ç»†æ•°æ®
        print("\nğŸ” 3. åŒæ­¥åº“å­˜æ˜ç»†æ•°æ®...")
        inventory_result = sync_jobs.sync_inventory_details()
        results['tasks'].append({
            'task': 'inventory_details',
            'result': inventory_result
        })
        
        if inventory_result.get('status') == 'success':
            print(f"âœ… åº“å­˜æ˜ç»†æ•°æ®åŒæ­¥æˆåŠŸ: {inventory_result.get('data_count', 0)} æ¡æ•°æ®")
        else:
            print(f"âŒ åº“å­˜æ˜ç»†æ•°æ®åŒæ­¥å¤±è´¥: {inventory_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # 4. è·å–åŒæ­¥çŠ¶æ€
        print("\nğŸ“‹ 4. è·å–åŒæ­¥çŠ¶æ€...")
        sync_status = sync_jobs.get_sync_status()
        results['sync_status'] = sync_status
        
        print("ğŸ“Š åŒæ­¥çŠ¶æ€æ±‡æ€»:")
        if 'merge_summary' in sync_status:
            summary = sync_status['merge_summary']
            print(f"   åº“å­˜ç‚¹æ€»æ•°: {summary.get('total_points', 0)}")
            print(f"   EUåº“å­˜ç‚¹æ•°: {summary.get('eu_points', 0)}")
            print(f"   éEUåº“å­˜ç‚¹æ•°: {summary.get('non_eu_points', 0)}")
            print(f"   åˆå¹¶è®°å½•æ•°: {summary.get('merged_records', 0)}")
        
        # 5. æ˜¾ç¤ºæœ€è¿‘ä»»åŠ¡
        print("\nğŸ• æœ€è¿‘ä»»åŠ¡:")
        recent_tasks = sync_status.get('recent_tasks', [])
        for task in recent_tasks[:5]:  # æ˜¾ç¤ºæœ€è¿‘5ä¸ªä»»åŠ¡
            print(f"   {task.get('task_type')}: {task.get('status')} ({task.get('created_at')})")
        
    except Exception as e:
        print(f"ğŸš¨ æ•°æ®åŒæ­¥æ‰§è¡Œå¤±è´¥: {e}")
        results['error'] = str(e)
        return False
    
    finally:
        # ä¿å­˜æ‰§è¡Œç»“æœ
        results['end_time'] = datetime.now().isoformat()
        results['duration'] = str(datetime.now() - datetime.fromisoformat(results['start_time']))
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        with open('sync_execution_result.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ æ‰§è¡Œç»“æœå·²ä¿å­˜åˆ°: sync_execution_result.json")
    
    return True

def sync_historical_data():
    """åŒæ­¥å†å²æ•°æ®ï¼ˆå¯é€‰ï¼‰"""
    print("\nğŸ“ˆ å¼€å§‹åŒæ­¥å†å²æ•°æ®...")
    
    sync_jobs = SyncJobs()
    
    # åŒæ­¥è¿‡å»7å¤©çš„äº§å“åˆ†ææ•°æ®
    print("ğŸ“Š åŒæ­¥è¿‡å»7å¤©çš„äº§å“åˆ†ææ•°æ®...")
    history_result = sync_jobs.sync_product_analytics_history(days=7)
    
    return history_result

if __name__ == "__main__":
    print("=" * 60)
    print("èµ›ç‹ERPæ•°æ®åŒæ­¥ç³»ç»Ÿ")
    print("=" * 60)
    
    # è·å–APIé…ç½®
    api_config = settings.get('api', {})
    print(f"APIé…ç½®:")
    print(f"  Base URL: {api_config.get('base_url', 'N/A')}")
    print(f"  Client ID: {api_config.get('client_id', 'N/A')}")
    
    # ç¡®è®¤æ‰§è¡Œ
    print("\nâš ï¸  ç¡®è®¤æ‰§è¡Œæ•°æ®åŒæ­¥?")
    print("è¿™å°†ä»èµ›ç‹ERP APIè·å–æœ€æ–°æ•°æ®å¹¶åŒæ­¥åˆ°æœ¬åœ°æ•°æ®åº“")
    
    try:
        choice = input("\næŒ‰Enterç»§ç»­ï¼Œæˆ–è¾“å…¥ 'history' åŒæ­¥å†å²æ•°æ®: ").strip().lower()
        
        if choice == 'history':
            result = sync_historical_data()
            print(f"\nå†å²æ•°æ®åŒæ­¥ç»“æœ: {result}")
        else:
            success = main()
            if success:
                print("\nğŸ‰ æ•°æ®åŒæ­¥æ‰§è¡Œå®Œæˆ!")
            else:
                print("\nâŒ æ•°æ®åŒæ­¥æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
                sys.exit(1)
                
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nğŸš¨ æ‰§è¡Œé”™è¯¯: {e}")
        sys.exit(1)