#!/usr/bin/env python3
"""
30å¤©å›è¡¥åŒæ­¥è„šæœ¬ - æ‰§è¡Œ30å¤©äº§å“åˆ†ææ•°æ®å›è¡¥ + FBAåº“å­˜ + åº“å­˜æ˜ç»†åŒæ­¥
"""

import sys
import os
from datetime import datetime, date, timedelta
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.scheduler.sync_jobs import SyncJobs
from src.config.settings import settings
from src.utils.logging_utils import setup_logging

def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œ30å¤©å›è¡¥ + å®Œæ•´æ•°æ®åŒæ­¥"""
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ30å¤©å›è¡¥ + å®Œæ•´æ•°æ®åŒæ­¥...")
    print(f"ğŸ“… æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    # åˆå§‹åŒ–åŒæ­¥ä½œä¸š
    sync_jobs = SyncJobs()
    start_time = datetime.now()
    
    # æ‰§è¡Œç»“æœæ±‡æ€»
    results = {
        'start_time': start_time.isoformat(),
        'tasks': []
    }
    
    # è·å–APIé…ç½®
    api_config = settings.get('api', {})
    print(f"APIé…ç½®:")
    print(f"  Base URL: {api_config.get('base_url', 'N/A')}")

    # å¯åŠ¨å‰å‡­æ®/ä»¤ç‰Œé¢„æ£€
    try:
        from src.config.secure_config import config
        from src.auth.oauth_client import oauth_client
        creds = config.get_api_credentials()
        print(f"  Client ID: {creds.client_id}")
        # è¯•å›¾è·å–ä¸€æ¬¡è®¿é—®ä»¤ç‰Œ
        token = oauth_client.get_access_token()
        if not token:
            raise RuntimeError("æ— æ³•è·å–è®¿é—®ä»¤ç‰Œï¼Œè¯·æ£€æŸ¥ SELLFOX_CLIENT_ID/SELLFOX_CLIENT_SECRET æ˜¯å¦æ­£ç¡®")
        print("  è®¿é—®ä»¤ç‰Œ: å·²è·å–")
    except Exception as precheck_err:
        print(f"âŒ å‡­æ®é¢„æ£€å¤±è´¥: {precheck_err}")
        raise
    
    try:
        # WebçŠ¶æ€é›†æˆ - æŠ¥å‘Šå¼€å§‹
        from src.utils.web_integration import report_status, report_progress, report_error, report_completed
        
        report_status('started', '30å¤©å›è¡¥æ•°æ®åŒæ­¥å·²å¯åŠ¨')
        
        # 1. å›è¡¥æœ€è¿‘30å¤©çš„äº§å“åˆ†ææ•°æ®
        print("\nğŸ“Š 1. å›è¡¥æœ€è¿‘30å¤©çš„äº§å“åˆ†ææ•°æ®...")
        report_progress('æ­£åœ¨å›è¡¥30å¤©äº§å“åˆ†ææ•°æ®', 10)
        
        backfill_result = sync_jobs.sync_product_analytics_history(days=30)
        results['tasks'].append({
            'task': 'product_analytics_30day_backfill',
            'result': backfill_result
        })
        
        if backfill_result.get('status') == 'completed':
            success_count = backfill_result.get('success_count', 0)
            failure_count = backfill_result.get('failure_count', 0)
            print(f"âœ… 30å¤©äº§å“åˆ†ææ•°æ®å›è¡¥å®Œæˆ")
            print(f"   æˆåŠŸåŒæ­¥: {success_count} å¤©")
            print(f"   å¤±è´¥åŒæ­¥: {failure_count} å¤©")
            
            # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœè¯¦æƒ…
            results_list = backfill_result.get('results', [])
            if results_list:
                print("   è¿‘5å¤©åŒæ­¥ç»“æœ:")
                for i, result in enumerate(results_list[:5]):
                    status_icon = "âœ…" if result.get('status') == 'success' else "âŒ"
                    data_date = result.get('data_date', 'N/A')
                    processed_count = result.get('processed_count', result.get('raw_count', 0))
                    print(f"     {status_icon} {data_date}: {processed_count} æ¡è®°å½•")
        else:
            print(f"âŒ 30å¤©äº§å“åˆ†ææ•°æ®å›è¡¥å¤±è´¥: {backfill_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            report_error(f"30å¤©æ•°æ®å›è¡¥å¤±è´¥: {backfill_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # 2. åŒæ­¥FBAåº“å­˜æ•°æ®
        print("\nğŸ“¦ 2. åŒæ­¥FBAåº“å­˜æ•°æ®...")
        report_progress('æ­£åœ¨åŒæ­¥FBAåº“å­˜æ•°æ®', 60)
        fba_result = sync_jobs.sync_fba_inventory()
        results['tasks'].append({
            'task': 'fba_inventory',
            'result': fba_result
        })
        
        if fba_result.get('status') == 'success':
            print(f"âœ… FBAåº“å­˜æ•°æ®åŒæ­¥æˆåŠŸ: {fba_result.get('data_count', 0)} æ¡æ•°æ®")
        else:
            print(f"âŒ FBAåº“å­˜æ•°æ®åŒæ­¥å¤±è´¥: {fba_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            report_error(f"FBAåº“å­˜æ•°æ®åŒæ­¥å¤±è´¥: {fba_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # 3. åŒæ­¥åº“å­˜æ˜ç»†æ•°æ®
        print("\nğŸ” 3. åŒæ­¥åº“å­˜æ˜ç»†æ•°æ®...")
        report_progress('æ­£åœ¨åŒæ­¥åº“å­˜æ˜ç»†æ•°æ®', 80)
        inventory_result = sync_jobs.sync_inventory_details()
        results['tasks'].append({
            'task': 'inventory_details',
            'result': inventory_result
        })
        
        if inventory_result.get('status') == 'success':
            print(f"âœ… åº“å­˜æ˜ç»†æ•°æ®åŒæ­¥æˆåŠŸ: {inventory_result.get('data_count', 0)} æ¡æ•°æ®")
        else:
            print(f"âŒ åº“å­˜æ˜ç»†æ•°æ®åŒæ­¥å¤±è´¥: {inventory_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            report_error(f"åº“å­˜æ˜ç»†æ•°æ®åŒæ­¥å¤±è´¥: {inventory_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # 4. è·å–åŒæ­¥çŠ¶æ€
        print("\nğŸ“‹ 4. è·å–åŒæ­¥çŠ¶æ€...")
        sync_status = sync_jobs.get_sync_status()
        results['sync_status'] = sync_status
        
        print("ğŸ“Š åŒæ­¥çŠ¶æ€æ±‡æ€»:")
        if 'merge_summary' in sync_status:
            summary = sync_status['merge_summary']
            print(f"   åº“å­˜ç‚¹æ€»æ•°: {summary.get('total_points', 0)}")
            print(f"   EUåº“å­˜ç‚¹æ•°: {summary.get('eu_points', 0)}")
            print(f"   éEUåº“å­˜ç‚¹æ•°: {summary.get('non_eu_points', 0)}")
            print(f"   åˆå¹¶è®°å½•æ•°: {summary.get('merged_records', 0)}")
        
        # 5. æ˜¾ç¤ºæœ€è¿‘ä»»åŠ¡
        print("\nğŸ• æœ€è¿‘ä»»åŠ¡:")
        recent_tasks = sync_status.get('recent_tasks', [])
        for task in recent_tasks[:8]:  # æ˜¾ç¤ºæœ€è¿‘8ä¸ªä»»åŠ¡
            task_type = task.get('task_type', 'unknown')
            status_icon = "âœ…" if task.get('status') == 'success' else "âŒ" if task.get('status') == 'failed' else "ğŸ”„"
            created_at = task.get('created_at', 'N/A')
            data_date = task.get('data_date') or ''
            print(f"   {status_icon} {task_type} {data_date}: {task.get('status')} ({created_at})")
        
        # 6. éªŒè¯æ•°æ®
        print("\nğŸ” 5. éªŒè¯åŒæ­¥æ•°æ®...")
        from src.database import db_manager
        
        # æ£€æŸ¥äº§å“åˆ†ææ•°æ®
        analytics_count_row = db_manager.execute_single("SELECT COUNT(*) AS count FROM product_analytics")
        analytics_count = analytics_count_row['count'] if analytics_count_row else 0
        print(f"   äº§å“åˆ†ææ•°æ®æ€»æ•°: {analytics_count}")
        
        # æ£€æŸ¥æœ€è¿‘30å¤©çš„æ•°æ®åˆ†å¸ƒ
        if analytics_count > 0:
            date_distribution_rows = db_manager.execute_query(
                """
                SELECT data_date, COUNT(*) as count 
                FROM product_analytics 
                WHERE data_date >= CURRENT_DATE - INTERVAL '30 days'
                GROUP BY data_date 
                ORDER BY data_date DESC 
                LIMIT 10
                """
            )
            print("   æœ€è¿‘10å¤©æ•°æ®åˆ†å¸ƒ:")
            for row in date_distribution_rows:
                print(f"     {row.get('data_date')}: {row.get('count')} æ¡è®°å½•")
        
        # æ£€æŸ¥FBAåº“å­˜æ•°æ®
        fba_count_row = db_manager.execute_single("SELECT COUNT(*) AS count FROM fba_inventory")
        fba_count = fba_count_row['count'] if fba_count_row else 0
        print(f"   FBAåº“å­˜æ•°æ®æ€»æ•°: {fba_count}")
        
        # æ£€æŸ¥åº“å­˜æ˜ç»†æ•°æ®
        inventory_details_count_row = db_manager.execute_single("SELECT COUNT(*) AS count FROM inventory_details")
        inventory_details_count = inventory_details_count_row['count'] if inventory_details_count_row else 0
        print(f"   åº“å­˜æ˜ç»†æ•°æ®æ€»æ•°: {inventory_details_count}")
        
        # WebçŠ¶æ€é›†æˆ - æŠ¥å‘Šå®Œæˆ
        end_time = datetime.now()
        duration = end_time - start_time
        duration_seconds = duration.total_seconds()
        
        # è®¡ç®—æ€»å¤„ç†è®°å½•æ•°
        total_records = 0
        for task in results['tasks']:
            task_result = task['result']
            if task_result.get('status') in ['success', 'completed']:
                if task['task'] == 'product_analytics_30day_backfill':
                    # 30å¤©å›è¡¥ä»»åŠ¡ï¼Œè®¡ç®—æ‰€æœ‰æˆåŠŸæ—¥æœŸçš„è®°å½•æ•°
                    backfill_results = task_result.get('results', [])
                    for day_result in backfill_results:
                        if day_result.get('status') == 'success':
                            total_records += day_result.get('processed_count', day_result.get('raw_count', 0))
                else:
                    total_records += task_result.get('processed_count', task_result.get('data_count', 0))
        
        report_completed(total_records, duration_seconds)
        
    except Exception as e:
        print(f"ğŸš¨ æ•°æ®åŒæ­¥æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        print("é”™è¯¯è¯¦æƒ…:")
        print(traceback.format_exc())
        results['error'] = str(e)
        report_error(str(e))
        return False
    
    finally:
        # ä¿å­˜æ‰§è¡Œç»“æœ
        results['end_time'] = datetime.now().isoformat()
        final_duration = datetime.now() - start_time
        results['duration'] = str(final_duration)
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        with open('sync_30day_backfill_result.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ æ‰§è¡Œç»“æœå·²ä¿å­˜åˆ°: sync_30day_backfill_result.json")
        print(f"â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {final_duration}")
    
    print("\nğŸ‰ 30å¤©å›è¡¥ + å®Œæ•´æ•°æ®åŒæ­¥æ‰§è¡Œå®Œæˆ!")
    return True

if __name__ == "__main__":
    print("=" * 70)
    print("èµ›ç‹ERPæ•°æ®åŒæ­¥ç³»ç»Ÿ - 30å¤©å›è¡¥ + å®Œæ•´åŒæ­¥")
    print("=" * 70)
    
    success = main()
    if not success:
        sys.exit(1)