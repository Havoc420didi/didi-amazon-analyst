#!/usr/bin/env python3
"""
ç«‹å³æ‰§è¡Œæ•°æ®åŒæ­¥è„šæœ¬ - éäº¤äº’å¼
ä½¿ç”¨éªŒè¯è¿‡çš„APIå‡­æ®æ‰§è¡Œæ‰€æœ‰æ•°æ®ç±»å‹çš„åŒæ­¥
"""

import sys
import os
import argparse
from datetime import datetime, date, timedelta
import json
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.scheduler.sync_jobs import SyncJobs
from src.config.settings import settings
from src.utils.logging_utils import setup_logging

def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„æ•°æ®åŒæ­¥ï¼Œæ”¯æŒ30å¤©å†å²æ•°æ®å›å¡«"""
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ
    parser = argparse.ArgumentParser(description='èµ›ç‹ERPæ•°æ®åŒæ­¥è„šæœ¬')
    parser.add_argument('--days', type=int, default=1, 
                       help="åŒæ­¥å¤šå°‘å¤©çš„å†å²äº§å“åˆ†ææ•°æ®ï¼Œé»˜è®¤1å¤©ï¼Œå¯è®¾ä¸º30è¿›è¡Œ30å¤©å®Œæ•´å›å¡«")
    parser.add_argument('--type', choices=['analytics', 'fba', 'inventory', 'all'], 
                       default='all', help="åŒæ­¥ç±»å‹ï¼šanalytics(ä»…äº§å“åˆ†æ)ã€fbaã€inventoryã€all(å…¨éƒ¨)")
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹æ‰§è¡Œèµ›ç‹ERPæ•°æ®åŒæ­¥...")
    print(f"ğŸ“… æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ¯ åŒæ­¥æ¨¡å¼: {args.days}å¤©å†å²æ•°æ® + {args.type}ç±»å‹")
    if args.days == 30:
        print("ğŸ“Š æ¨¡å¼: 30å¤©å®Œæ•´å†å²æ•°æ®å›å¡«ï¼ˆåŒ…å«åº“å­˜åˆå¹¶ï¼‰")
    
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    # åˆå§‹åŒ–åŒæ­¥ä½œä¸š
    sync_jobs = SyncJobs()
    start_time = datetime.now()
    
    # æ‰§è¡Œç»“æœæ±‡æ€»
    results = {
        'start_time': start_time.isoformat(),
        'tasks': []
    }
    
    # è·å–APIé…ç½®
    api_config = settings.get('api', {})
    print(f"APIé…ç½®:")
    print(f"  Base URL: {api_config.get('base_url', 'N/A')}")

    # å¯åŠ¨å‰å‡­æ®/ä»¤ç‰Œé¢„æ£€
    try:
        from src.config.secure_config import config
        from src.auth.oauth_client import oauth_client
        creds = config.get_api_credentials()
        print(f"  Client ID: {creds.client_id}")
        # è¯•å›¾è·å–ä¸€æ¬¡è®¿é—®ä»¤ç‰Œ
        token = oauth_client.get_access_token()
        if not token:
            raise RuntimeError("æ— æ³•è·å–è®¿é—®ä»¤ç‰Œï¼Œè¯·æ£€æŸ¥ SELLFOX_CLIENT_ID/SELLFOX_CLIENT_SECRET æ˜¯å¦æ­£ç¡®")
        print("  è®¿é—®ä»¤ç‰Œ: å·²è·å–")
    except Exception as precheck_err:
        print(f"âŒ å‡­æ®é¢„æ£€å¤±è´¥: {precheck_err}")
        raise
    
    try:
        # WebçŠ¶æ€é›†æˆ - æŠ¥å‘Šå¼€å§‹
        from src.utils.web_integration import report_status, report_progress, report_error, report_completed
        
        report_status('started', 'èµ›ç‹ERPæ•°æ®åŒæ­¥å·²å¯åŠ¨')
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©åŒæ­¥ç­–ç•¥
        if args.days == 30:
            print("\nğŸ“Š 1. åŒæ­¥30å¤©å†å²äº§å“åˆ†ææ•°æ®...")
            report_progress('æ­£åœ¨åŒæ­¥30å¤©å†å²æ•°æ®', 20)
            analytics_result = sync_jobs.sync_product_analytics_history(days=30)
            results['tasks'].append({
                'task': 'product_analytics_30day',
                'days': 30,
                'result': analytics_result
            })
        else:
            print("\nğŸ“Š 1. åŒæ­¥äº§å“åˆ†ææ•°æ®ï¼ˆæ˜¨å¤©ï¼‰...")
            report_progress('æ­£åœ¨åŒæ­¥äº§å“åˆ†ææ•°æ®', 20)
            yesterday = (date.today() - timedelta(days=1)).strftime('%Y-%m-%d')
            analytics_result = sync_jobs.sync_product_analytics_by_date(yesterday)
            results['tasks'].append({
                'task': 'product_analytics_yesterday',
                'date': yesterday,
                'result': analytics_result
            })
        
        if analytics_result.get('status') == 'success':
            print(f"âœ… äº§å“åˆ†ææ•°æ®åŒæ­¥æˆåŠŸ: {analytics_result.get('raw_count', 0)} æ¡åŸå§‹æ•°æ®")
            print(f"   å¤„ç†æˆåŠŸ: {analytics_result.get('processed_count', 0)} æ¡")
            print(f"   åº“å­˜åˆå¹¶: {analytics_result.get('merged_count', 0)} æ¡")
        else:
            print(f"âŒ äº§å“åˆ†ææ•°æ®åŒæ­¥å¤±è´¥: {analytics_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            report_error(f"äº§å“åˆ†ææ•°æ®åŒæ­¥å¤±è´¥: {analytics_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # 2. åŒæ­¥FBAåº“å­˜æ•°æ®
        print("\nğŸ“¦ 2. åŒæ­¥FBAåº“å­˜æ•°æ®...")
        report_progress('æ­£åœ¨åŒæ­¥FBAåº“å­˜æ•°æ®', 50)
        fba_result = sync_jobs.sync_fba_inventory()
        results['tasks'].append({
            'task': 'fba_inventory',
            'result': fba_result
        })
        
        if fba_result.get('status') == 'success':
            print(f"âœ… FBAåº“å­˜æ•°æ®åŒæ­¥æˆåŠŸ: {fba_result.get('data_count', 0)} æ¡æ•°æ®")
        else:
            print(f"âŒ FBAåº“å­˜æ•°æ®åŒæ­¥å¤±è´¥: {fba_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            report_error(f"FBAåº“å­˜æ•°æ®åŒæ­¥å¤±è´¥: {fba_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # 3. åŒæ­¥åº“å­˜æ˜ç»†æ•°æ®
        print("\nğŸ” 3. åŒæ­¥åº“å­˜æ˜ç»†æ•°æ®...")
        report_progress('æ­£åœ¨åŒæ­¥åº“å­˜æ˜ç»†æ•°æ®', 80)
        inventory_result = sync_jobs.sync_inventory_details()
        results['tasks'].append({
            'task': 'inventory_details',
            'result': inventory_result
        })
        
        if inventory_result.get('status') == 'success':
            print(f"âœ… åº“å­˜æ˜ç»†æ•°æ®åŒæ­¥æˆåŠŸ: {inventory_result.get('data_count', 0)} æ¡æ•°æ®")
        else:
            print(f"âŒ åº“å­˜æ˜ç»†æ•°æ®åŒæ­¥å¤±è´¥: {inventory_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            report_error(f"åº“å­˜æ˜ç»†æ•°æ®åŒæ­¥å¤±è´¥: {inventory_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # 4. è·å–åŒæ­¥çŠ¶æ€
        print("\nğŸ“‹ 4. è·å–åŒæ­¥çŠ¶æ€...")
        sync_status = sync_jobs.get_sync_status()
        results['sync_status'] = sync_status
        
        print("ğŸ“Š åŒæ­¥çŠ¶æ€æ±‡æ€»:")
        if 'merge_summary' in sync_status:
            summary = sync_status['merge_summary']
            print(f"   åº“å­˜ç‚¹æ€»æ•°: {summary.get('total_points', 0)}")
            print(f"   EUåº“å­˜ç‚¹æ•°: {summary.get('eu_points', 0)}")
            print(f"   éEUåº“å­˜ç‚¹æ•°: {summary.get('non_eu_points', 0)}")
            print(f"   åˆå¹¶è®°å½•æ•°: {summary.get('merged_records', 0)}")
        
        # 5. æ˜¾ç¤ºæœ€è¿‘ä»»åŠ¡
        print("\nğŸ• æœ€è¿‘ä»»åŠ¡:")
        recent_tasks = sync_status.get('recent_tasks', [])
        for task in recent_tasks[:5]:  # æ˜¾ç¤ºæœ€è¿‘5ä¸ªä»»åŠ¡
            print(f"   {task.get('task_type')}: {task.get('status')} ({task.get('created_at')})")
        
        # 6. éªŒè¯æ•°æ®
        print("\nğŸ” 5. éªŒè¯åŒæ­¥æ•°æ®...")
        from src.database import db_manager
        
        # æ£€æŸ¥äº§å“åˆ†ææ•°æ®
        analytics_count_row = db_manager.execute_single("SELECT COUNT(*) AS count FROM product_analytics")
        analytics_count = analytics_count_row['count'] if analytics_count_row else 0
        print(f"   äº§å“åˆ†ææ•°æ®æ€»æ•°: {analytics_count}")
        
        if analytics_count > 0:
            ad_sample_rows = db_manager.execute_query(
                "SELECT sku, ad_cost, ad_sales FROM product_analytics WHERE ad_cost > 0 ORDER BY data_date DESC LIMIT 3"
            )
            print(f"   æœ‰å¹¿å‘Šæ•°æ®çš„è®°å½•æ•°ç¤ºä¾‹: {len(ad_sample_rows)}")
            if ad_sample_rows:
                print("   å¹¿å‘Šæ•°æ®ç¤ºä¾‹:")
                for row in ad_sample_rows:
                    print(f"     SKU: {row.get('sku')}, å¹¿å‘ŠèŠ±è´¹: {row.get('ad_cost')}, å¹¿å‘Šé”€å”®: {row.get('ad_sales')}")
        
        # æ£€æŸ¥FBAåº“å­˜æ•°æ®
        fba_count_row = db_manager.execute_single("SELECT COUNT(*) AS count FROM fba_inventory")
        fba_count = fba_count_row['count'] if fba_count_row else 0
        print(f"   FBAåº“å­˜æ•°æ®æ€»æ•°: {fba_count}")
        
        if fba_count > 0:
            fba_sample_rows = db_manager.execute_query(
                "SELECT sku, available, total_inventory FROM fba_inventory ORDER BY snapshot_date DESC NULLS LAST LIMIT 3"
            )
            print("   FBAåº“å­˜æ•°æ®ç¤ºä¾‹:")
            for row in fba_sample_rows:
                print(f"     SKU: {row.get('sku')}, å¯ç”¨åº“å­˜: {row.get('available')}, æ€»åº“å­˜: {row.get('total_inventory')}")
        
        # WebçŠ¶æ€é›†æˆ - æŠ¥å‘Šå®Œæˆ
        end_time = datetime.now()
        duration = end_time - start_time
        duration_seconds = duration.total_seconds()
        
        total_records = sum(task['result'].get('processed_count', task['result'].get('data_count', 0)) 
                          for task in results['tasks'] if task['result'].get('status') == 'success')
        
        report_completed(total_records, duration_seconds)
        
    except Exception as e:
        print(f"ğŸš¨ æ•°æ®åŒæ­¥æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        print("é”™è¯¯è¯¦æƒ…:")
        print(traceback.format_exc())
        results['error'] = str(e)
        report_error(str(e))
        return False
    
    finally:
        # ä¿å­˜æ‰§è¡Œç»“æœ
        results['end_time'] = datetime.now().isoformat()
        final_duration = datetime.now() - start_time
        results['duration'] = str(final_duration)
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        with open('sync_execution_result.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ æ‰§è¡Œç»“æœå·²ä¿å­˜åˆ°: sync_execution_result.json")
        print(f"â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {final_duration}")
    
    print("\nğŸ‰ æ•°æ®åŒæ­¥æ‰§è¡Œå®Œæˆ!")
    return True

if __name__ == "__main__":
    print("=" * 60)
    print("èµ›ç‹ERPæ•°æ®åŒæ­¥ç³»ç»Ÿ - éäº¤äº’å¼")
    print("=" * 60)
    
    success = main()
    if not success:
        sys.exit(1)